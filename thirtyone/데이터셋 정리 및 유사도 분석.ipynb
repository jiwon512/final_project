{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e3a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rcParams\n",
    "import warnings, logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c43c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_list = pd.read_csv(\"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/광고도메인리스트.csv\")\n",
    "time_df = pd.read_csv(\"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/수정_시간별적립보고서(최종).csv\")\n",
    "click = pd.read_csv(\"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/유저테이블.csv\")\n",
    "cv_goal = pd.read_csv(\"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/cv_goal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef3fbe",
   "metadata": {},
   "source": [
    "# ads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7cb374",
   "metadata": {},
   "source": [
    "## ads_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b9c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epire 컬럼 만들기\n",
    "\n",
    "# 1. 기준일 설정\n",
    "today = pd.to_datetime('today').date()\n",
    "\n",
    "# 2. expire 컬럼 초기화 (기본값 0)\n",
    "ads_list['expire'] = 0\n",
    "\n",
    "# 3. 실제 날짜 형태 필터링 및 만료 체크\n",
    "def check_expire(date_str):\n",
    "    try:\n",
    "        # 9999나 0000이 포함된 경우는 무기한으로 처리 (expire = 0)\n",
    "        if '9999' in str(date_str) or '0000' in str(date_str):\n",
    "            return 0\n",
    "        \n",
    "        # 실제 날짜로 변환 시도\n",
    "        end_date = pd.to_datetime(date_str).date()\n",
    "        \n",
    "        # 오늘보다 이전이면 만료 (1), 이후면 유효 (0)\n",
    "        return 1 if end_date < today else 0\n",
    "        \n",
    "    except:\n",
    "        # 변환 실패하면 무기한으로 처리\n",
    "        return 0\n",
    "\n",
    "# 적용\n",
    "ads_list['expire'] = ads_list['ads_edate'].apply(check_expire)\n",
    "ads_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00113f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ads_seg 테이블 만들기\n",
    "\n",
    "click['click_date'] = pd.to_datetime(click['click_date'])\n",
    "\n",
    "ads_seg = click.groupby('ads_idx').agg({\n",
    "    'mda_idx': 'nunique',        # 매체사 수\n",
    "    'dvc_idx': 'nunique',        # 유니크 사용자 수 (있다면)\n",
    "    'click_key': 'count',\n",
    "    'conversion': 'sum',\n",
    "    'ads_category': 'first',\n",
    "    'domain': 'first',\n",
    "    'ads_os_type': 'first',\n",
    "    'ads_order': 'first',\n",
    "    'ctit': ['mean', 'median'],\n",
    "    'ads_rejoin_type': 'first',\n",
    "    'contract_price': 'first',\n",
    "    'media_price': 'first',\n",
    "    'click_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# 컬럼명 변경\n",
    "ads_seg.columns = ['ads_idx', 'media_count', 'user_count', 'total_clicks', 'total_conversions', 'ads_category', 'domain', 'ads_os_type', \n",
    "                   'ads_order', 'ctit_mean', 'ctit_median', 'ads_rejoin_type', 'contract_price', 'media_price', 'first_click', 'last_click']\n",
    "\n",
    "# (ads_name) 컬럼 붙이기\n",
    "ads_seg = ads_seg.merge(ads_list[['ads_idx', 'ads_name', 'ads_sdate', 'expire']], on='ads_idx', how='left')\n",
    "\n",
    "# 광고 기간 및 일평균 전환수 계산\n",
    "ads_seg['days_active'] = (ads_seg['last_click'] - ads_seg['first_click']).dt.days + 1\n",
    "ads_seg['daily_avg_conversions'] = ads_seg['total_conversions'] / ads_seg['days_active']\n",
    "\n",
    "\n",
    "# 추후에 시간 datetime으로 바꿔서 active 여부랑 기간 넣기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8bef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvr 구하기\n",
    "# 마진 구하기\n",
    "\n",
    "ads_seg['cvr'] = (ads_seg['total_conversions'] / ads_seg['total_clicks']).round(1)\n",
    "ads_seg['margin'] = (ads_seg['contract_price'] - ads_seg['media_price'])\n",
    "ads_seg['roi'] = (ads_seg['margin'] / ads_seg['media_price']).round(1)\n",
    "ads_seg['total_net_return'] = ads_seg['margin'] * ads_seg['total_conversions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f689fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 광고 사이즈 구분\n",
    "\n",
    "def standard_tier_classification(df):\n",
    "    # daily_clicks 계산\n",
    "    df['daily_clicks'] = df['total_clicks'] / df['days_active']\n",
    "    \n",
    "    # 점수 계산 (동일)\n",
    "    def get_percentile_score(value, series):\n",
    "        if value >= series.quantile(0.99): return 4\n",
    "        elif value >= series.quantile(0.90): return 3  \n",
    "        elif value >= series.quantile(0.70): return 2\n",
    "        elif value >= series.quantile(0.40): return 1\n",
    "        else: return 0\n",
    "    \n",
    "    df['media_score'] = df['media_count'].apply(lambda x: get_percentile_score(x, df['media_count']))\n",
    "    df['conv_score'] = df['daily_avg_conversions'].apply(lambda x: get_percentile_score(x, df['daily_avg_conversions']))\n",
    "    df['clicks_score'] = df['daily_clicks'].apply(lambda x: get_percentile_score(x, df['daily_clicks']))\n",
    "    df['stability_score'] = df['days_active'].apply(lambda x: get_percentile_score(x, df['days_active']))\n",
    "    df['cvr_score'] = df['cvr'].apply(lambda x: get_percentile_score(x, df['cvr']))\n",
    "    \n",
    "    df['total_score'] = (df['media_score'] + df['conv_score'] + df['clicks_score'] + \n",
    "                        df['stability_score'] + df['cvr_score'])\n",
    "    \n",
    "    # 표준 분류 (피라미드 형태)\n",
    "    def get_standard_tier(score, score_series):\n",
    "        if score >= score_series.quantile(0.995): return 'MEGA'    # 상위 5%\n",
    "        elif score >= score_series.quantile(0.80): return 'LARGE'  # 상위 20%\n",
    "        elif score >= score_series.quantile(0.30): return 'MEDIUM' # 상위 70% (가장 많음)\n",
    "        else: return 'SMALL'                                      # 하위 30%\n",
    "    \n",
    "    df['ads_size'] = df['total_score'].apply(lambda x: get_standard_tier(x, df['total_score']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "ads_seg = standard_tier_classification(ads_seg)\n",
    "\n",
    "print(\"백분위 기준 분류:\")\n",
    "print(ads_seg['ads_size'].value_counts())\n",
    "print(f\"\\n분류 비율:\")\n",
    "print((ads_seg['ads_size'].value_counts() / len(ads_seg) * 100).round(1))\n",
    "print(ads_seg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a7b20",
   "metadata": {},
   "source": [
    "### cv_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M, A 컬럼 붙여 넣기\n",
    "\n",
    "# 먼저 M, A 컬럼 생성\n",
    "cv_goal['M'] = (cv_goal['sch_type'] == 'M').astype(int)\n",
    "cv_goal['A'] = (cv_goal['sch_type'] == 'A').astype(int)\n",
    "\n",
    "# ads_idx 기준으로 그룹화하여 집계\n",
    "cv_goal_grouped = cv_goal.groupby('ads_idx').agg({\n",
    "    'mda_idx_arr': 'first',  # 첫 번째 값 사용 (M과 A가 다를 수 있으니 확인 필요)\n",
    "    'sch_sdatetime': 'first',  # 시작일은 첫 번째 값\n",
    "    'sch_edatetime': 'first',  # 종료일은 첫 번째 값\n",
    "    'sch_adv_pay': 'first',\n",
    "    'sch_ads_pay': 'first',\n",
    "    'sch_mda_pay': 'max',\n",
    "    'sch_clk_num': 'first',\n",
    "    'sch_turn_num': 'sum',  # turn_num은 합계가 적절할 수 있음\n",
    "    'M': 'max',  # M이 하나라도 있으면 1\n",
    "    'A': 'max'   # A가 하나라도 있으면 1\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"Original rows: {len(cv_goal)}\")\n",
    "print(f\"After grouping: {len(cv_goal_grouped)}\")\n",
    "print(\"\\nM, A 조합 분포:\")\n",
    "print(cv_goal_grouped[['M', 'A']].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aef49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ads_seg 랑 조인\n",
    "\n",
    "# ads_idx를 기준으로 조인\n",
    "merged_df = ads_seg.merge(\n",
    "    cv_goal_grouped[['ads_idx', 'mda_idx_arr', 'M', 'A']], \n",
    "    on='ads_idx', \n",
    "    how='left'  # 또는 'inner', 'outer' 등 필요에 따라\n",
    ")\n",
    "\n",
    "# 여러 컬럼을 한 번에 처리\n",
    "merged_df = merged_df.fillna({\n",
    "    'mda_idx_arr': 'None',\n",
    "    'M': 0,\n",
    "    'A': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M==1 인 것들 중에서  광고가 우선 배정되는 m__arr 와 실제 들어가는 광고 똑같은 것 알아보기 (jaccard 사용)\n",
    "\n",
    "m_ads = merged_df[merged_df['M']==1]\n",
    "\n",
    "# 1) time_df에서 ads_idx별 mda_idx 리스트 만들기\n",
    "time_mda = (\n",
    "    time_df\n",
    "      .dropna(subset=['ads_idx', 'mda_idx'])\n",
    "      .groupby('ads_idx')['mda_idx']\n",
    "      .unique()            # np.ndarray\n",
    "      .map(list)           # list로 변환\n",
    "      .rename('mda_idx_from_time')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 2) m_ads와 조인\n",
    "out = m_ads.merge(time_mda, on='ads_idx', how='left')\n",
    "\n",
    "# ------------------ 여기부터 교체/추가 ------------------\n",
    "\n",
    "def normalize_mda_list(x):\n",
    "    \"\"\"여러 형태(x)가 와도 [아이디, ...] 형태의 평평한 리스트로 표준화\"\"\"\n",
    "    # 결측/None 처리\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)) or (isinstance(x, str) and x.strip().lower() in {\"none\", \"nan\", \"\"}):\n",
    "        return []\n",
    "    # 문자열이면 안전 파싱 시도\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            x = ast.literal_eval(x)\n",
    "        except Exception:\n",
    "            # '1,2,3' 같은 단순 콤마 문자열 대응\n",
    "            return [i.strip() for i in x.split(',') if i.strip() != '']\n",
    "\n",
    "    # 튜플은 리스트로\n",
    "    if isinstance(x, tuple):\n",
    "        x = list(x)\n",
    "\n",
    "    # 리스트 계열은 내부 원소 평탄화\n",
    "    if isinstance(x, list):\n",
    "        flat = []\n",
    "        for e in x:\n",
    "            if e is None or (isinstance(e, float) and pd.isna(e)):\n",
    "                continue\n",
    "            if isinstance(e, tuple) or isinstance(e, list):\n",
    "                flat.extend(list(e))       # [(562,563)] → [562,563], [[562,563]] → [562,563]\n",
    "            else:\n",
    "                flat.append(e)\n",
    "        # 중복 제거(순서 보존)\n",
    "        seen = set()\n",
    "        dedup = []\n",
    "        for v in flat:\n",
    "            key = str(v)                   # 타입 혼합 대비\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                dedup.append(v)\n",
    "        return dedup\n",
    "\n",
    "    # 그 외 스칼라\n",
    "    return [x]\n",
    "\n",
    "# 두 컬럼 모두 동일 규칙으로 표준화\n",
    "out['mda_idx_arr_list']  = out['mda_idx_arr'].apply(normalize_mda_list)\n",
    "out['mda_idx_from_time'] = out['mda_idx_from_time'].apply(normalize_mda_list)\n",
    "\n",
    "# 4) 비교용: 집합(순서 무시)\n",
    "to_set = lambda v: set(map(str, v))   # 타입 혼합 대비 문자열화\n",
    "out['arr_set']  = out['mda_idx_arr_list'].apply(to_set)\n",
    "out['time_set'] = out['mda_idx_from_time'].apply(to_set)\n",
    "\n",
    "# 5) 비교 결과\n",
    "out['is_equal_unordered'] = (out['arr_set'] == out['time_set'])\n",
    "out['missing_in_arr'] = (out['time_set'] - out['arr_set']).apply(lambda s: sorted(s))\n",
    "out['extra_in_arr']   = (out['arr_set'] - out['time_set']).apply(lambda s: sorted(s))\n",
    "\n",
    "def jaccard(a, b):\n",
    "    if not a and not b:\n",
    "        return 1.0\n",
    "    return len(a & b) / len(a | b) if (a | b) else 0.0\n",
    "\n",
    "out['jaccard'] = [jaccard(a, b) for a, b in zip(out['arr_set'], out['time_set'])]\n",
    "\n",
    "# 우선순위 1순위가 실제 등장하는지\n",
    "out['top_priority_in_time'] = [\n",
    "    (str(lst[0]) in tset) if lst else False\n",
    "    for lst, tset in zip(out['mda_idx_arr_list'], out['time_set'])\n",
    "]\n",
    "\n",
    "# 6) 보기용 요약\n",
    "compare_cols = [\n",
    "    'ads_idx', 'mda_idx_arr_list', 'mda_idx_from_time',\n",
    "    'is_equal_unordered', 'missing_in_arr', 'extra_in_arr',\n",
    "    'jaccard', 'top_priority_in_time'\n",
    "]\n",
    "result_compare = out[compare_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정매체광고\n",
    "# mda_idx_from_time이 mda_idx_arr_list에 포함되거나 같은것만 뽑는거\n",
    "\n",
    "mask = [\n",
    "    all(m in row['mda_idx_arr_list'] for m in row['mda_idx_from_time'])\n",
    "    for _, row in result_compare.iterrows()\n",
    "]\n",
    "restricted_mda = result_compare[mask]\n",
    "\n",
    "restricted_mda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59861d0",
   "metadata": {},
   "source": [
    "### ads_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fddfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정매체광고x\n",
    "# 이거 반지정 아예 아닌거 나눠야하나?\n",
    "\n",
    "# 제외할 광고 아이디 (restricted_mda에서)\n",
    "exclude_ids = set(restricted_mda['ads_idx'].unique())\n",
    "\n",
    "# ads_seg에서 이 아이디들 아닌 행만 보기\n",
    "ads_seg_filter = merged_df[ ~merged_df['ads_idx'].isin(exclude_ids) ].copy()\n",
    "\n",
    "# (선택) 인덱스 리셋\n",
    "ads_seg_filter = ads_seg_filter.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42779d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expire 안된 애들 골라내기\n",
    "\n",
    "ads_pool= ads_seg_filter[ads_seg_filter['expire'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8013c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20d6fb2c",
   "metadata": {},
   "source": [
    "## media_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계: 매체사-광고 관계 추출\n",
    "media_ads_mapping = click[['mda_idx', 'ads_idx']].drop_duplicates()\n",
    "\n",
    "# 2단계: 광고 분류 정보 조인\n",
    "media_ads_mapping = media_ads_mapping.merge(\n",
    "    ads_seg[['ads_idx', 'ads_size']], \n",
    "    on='ads_idx', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3단계: 매체사별 광고 레벨 집계\n",
    "media_portfolio = media_ads_mapping.groupby(['mda_idx', 'ads_size']).size().unstack(fill_value=0)\n",
    "\n",
    "# 4단계: 총 광고 수 및 비율 계산\n",
    "media_portfolio['total_ads'] = media_portfolio.sum(axis=1)\n",
    "\n",
    "# 각 레벨별 비율 계산\n",
    "for level in ['MEGA', 'LARGE', 'MEDIUM', 'SMALL']:\n",
    "    if level in media_portfolio.columns:\n",
    "        media_portfolio[f'{level}_ratio'] = (\n",
    "            media_portfolio[level] / media_portfolio['total_ads'] * 100\n",
    "        ).round(1)\n",
    "\n",
    "# 5단계: 결과 확인\n",
    "print(\"매체사별 포트폴리오 (상위 10개):\")\n",
    "print(media_portfolio.sort_values('total_ads', ascending=False).head(10))\n",
    "\n",
    "# 6단계: 매체사 특성 분석\n",
    "print(\"\\n매체사 포트폴리오 요약:\")\n",
    "print(f\"총 매체사 수: {len(media_portfolio)}\")\n",
    "print(f\"평균 광고 보유 수: {media_portfolio['total_ads'].mean():.1f}\")\n",
    "print(f\"광고 10개 이상 보유 매체사: {(media_portfolio['total_ads'] >= 10).sum()}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ca051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 매체사 기본 정보 \n",
    "media_basic = click.groupby('mda_idx').agg({\n",
    "    'dvc_idx': 'nunique',        \n",
    "    'click_key': 'count',\n",
    "    'conversion': 'sum',\n",
    "    'click_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "media_basic.columns = ['mda_idx', 'user_count', 'total_clicks', 'total_conversions', 'first_click', 'last_click']\n",
    "\n",
    "# 기간 및 일평균 계산\n",
    "media_basic['days_active'] = (media_basic['last_click'] - media_basic['first_click']).dt.days + 1\n",
    "media_basic['daily_avg_conversions'] = media_basic['total_conversions'] / media_basic['days_active']\n",
    "\n",
    "# 2. 매체사-광고 관계\n",
    "media_ads_mapping = click[['mda_idx', 'ads_idx']].drop_duplicates()\n",
    "media_ads_mapping = media_ads_mapping.merge(\n",
    "    ads_seg[['ads_idx', 'ads_size']], \n",
    "    on='ads_idx', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. 포트폴리오 구성\n",
    "media_portfolio_composition = media_ads_mapping.groupby(['mda_idx', 'ads_size']).size().unstack(fill_value=0)\n",
    "media_portfolio_composition['total_ads'] = media_portfolio_composition.sum(axis=1)\n",
    "\n",
    "# 비율 계산\n",
    "for level in ['MEGA', 'LARGE', 'MEDIUM', 'SMALL']:\n",
    "    if level in media_portfolio_composition.columns:\n",
    "        media_portfolio_composition[f'{level}_ratio'] = (\n",
    "            media_portfolio_composition[level] / media_portfolio_composition['total_ads'] * 100\n",
    "        ).round(1)\n",
    "\n",
    "# 4. 최종 합치기\n",
    "media_portfolio = media_basic.merge(\n",
    "    media_portfolio_composition, \n",
    "    on='mda_idx', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "media_portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeef159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 매체사-광고 관계에 광고 속성 정보 추가\n",
    "media_ads_with_attributes = media_ads_mapping.merge(\n",
    "    ads_list[['ads_idx', 'ads_category', 'ads_os_type', 'domain']], \n",
    "    on='ads_idx', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 2. 각 속성별로 매체사별 분포 계산\n",
    "def calculate_attribute_distribution(df, attribute_col):\n",
    "    # 매체사별 해당 속성 분포\n",
    "    attr_dist = df.groupby(['mda_idx', attribute_col]).size().unstack(fill_value=0)\n",
    "    \n",
    "    # 총 광고 수로 나누어 비율 계산\n",
    "    attr_dist_pct = attr_dist.div(attr_dist.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # 컬럼명에 prefix 추가\n",
    "    attr_dist_pct.columns = [f'{attribute_col}_{col}_pct' for col in attr_dist_pct.columns]\n",
    "    \n",
    "    return attr_dist_pct\n",
    "\n",
    "# 3. 각 속성별 비율 계산\n",
    "category_dist = calculate_attribute_distribution(media_ads_with_attributes, 'ads_category')\n",
    "os_dist = calculate_attribute_distribution(media_ads_with_attributes, 'ads_os_type')  \n",
    "domain_dist = calculate_attribute_distribution(media_ads_with_attributes, 'domain')\n",
    "\n",
    "# 4. 모든 분포 정보를 기존 테이블에 조인\n",
    "media_portfolio = media_portfolio.merge(\n",
    "    category_dist, on='mda_idx', how='left'\n",
    ").merge(\n",
    "    os_dist, on='mda_idx', how='left'\n",
    ").merge(\n",
    "    domain_dist, on='mda_idx', how='left'\n",
    ")\n",
    "\n",
    "# 5. 결과 확인\n",
    "print(f\"최종 테이블 크기: {media_portfolio.shape}\")\n",
    "print(\"추가된 컬럼들:\")\n",
    "new_cols = [col for col in media_portfolio.columns if '_pct' in col]\n",
    "print(new_cols[:10])  # 처음 10개만 출력\n",
    "\n",
    "# 샘플 확인\n",
    "print(\"\\n매체사별 속성 분포 (상위 5개 매체사):\")\n",
    "sample_cols = ['mda_idx', 'total_ads'] + new_cols[:6]  # 샘플로 몇 개만\n",
    "print(media_portfolio[sample_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. click 데이터에서 순수익 계산\n",
    "click['profit_per_conversion'] = click['contract_price'] - click['media_price']\n",
    "\n",
    "# 2. 각 행별 실제 수익 계산 (전환이 발생한 경우만)\n",
    "click['actual_profit'] = click['profit_per_conversion'] * click['conversion']\n",
    "\n",
    "# 3. 매체사별 총 예상 수익 집계\n",
    "media_expected_profit = click.groupby('mda_idx')['actual_profit'].sum().reset_index()\n",
    "media_expected_profit.columns = ['mda_idx', 'expected_total_profit']\n",
    "\n",
    "# 4. media_portfolio에 조인\n",
    "media_portfolio = media_portfolio.merge(\n",
    "    media_expected_profit, \n",
    "    on='mda_idx', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# NaN 처리 (수익이 없는 매체사는 0)\n",
    "media_portfolio['expected_total_profit'] = (\n",
    "    media_portfolio['expected_total_profit'].fillna(0)\n",
    ")\n",
    "\n",
    "# 결과 확인\n",
    "print(\"매체사별 예상 수익 상위 10개:\")\n",
    "top_profit = media_portfolio.sort_values('expected_total_profit', ascending=False)\n",
    "print(top_profit[['mda_idx', 'total_ads', 'total_conversions', 'expected_total_profit']].head(10))\n",
    "\n",
    "print(f\"\\n전체 매체사 예상 수익 합계: {media_portfolio['expected_total_profit'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2f893",
   "metadata": {},
   "source": [
    "### media_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_media_companies(df, auto_thresholds=False, reduce_misc=True):\n",
    "    \"\"\"\n",
    "    매체사를 6가지 유형으로 분류 (기타 최소화 옵션 포함)\n",
    "    \"\"\"\n",
    "    THRESHOLDS = {\n",
    "        'total_ads_large': 115,        # 상위 10% (대량처리)\n",
    "        'total_ads_medium': 28,        # 상위 25% (안정공급)\n",
    "        'daily_conv_high': 500,        # 상위 10% (고성능)\n",
    "        'daily_conv_medium': 164,      # 상위 25% (중성능)\n",
    "        'days_active_stable': 25,      # 안정적 활동\n",
    "        'days_active_new': 15,         # 신규 기준\n",
    "        'conversion_rate_low': 0.001,  # 어뷰징 의심(0.1%)\n",
    "        'specialization_threshold': 50, # 도메인 특화 (%)\n",
    "        'mega_specialization': 70,     # MEGA 특화\n",
    "        'large_specialization': 80,    # LARGE 특화\n",
    "        'min_performance': 10,         # 최소 성과\n",
    "        'inactive_cutoff': '2025-08-23' # 비활성 기준일(8/23 포함 이전)\n",
    "    }\n",
    "    ABUSE_MIN_CLICKS = 1000\n",
    "\n",
    "    media_df = df.copy()\n",
    "\n",
    "    # 파생 지표\n",
    "    media_df['conversion_rate'] = media_df['total_conversions'] / media_df['total_clicks'].replace(0, np.nan)\n",
    "    media_df['conversion_rate'] = media_df['conversion_rate'].fillna(0)\n",
    "    media_df['last_click_dt'] = pd.to_datetime(media_df['last_click'], errors='coerce')\n",
    "    cutoff_date = pd.to_datetime(THRESHOLDS['inactive_cutoff'])\n",
    "\n",
    "    # (선택) 분위수 기반 자동 튜닝\n",
    "    def _maybe_autotune_thresholds(df, TH, enabled):\n",
    "        if not enabled: return TH\n",
    "        q = df.quantile\n",
    "        tuned = TH.copy()\n",
    "        tuned.update({\n",
    "            'total_ads_large': int(q(0.90)['total_ads']),\n",
    "            'total_ads_medium': int(q(0.75)['total_ads']),\n",
    "            'daily_conv_high': float(q(0.90)['daily_avg_conversions']),\n",
    "            'daily_conv_medium': float(q(0.75)['daily_avg_conversions']),\n",
    "            'days_active_stable': max(14, int(q(0.75)['days_active'])),\n",
    "            'days_active_new': int(q(0.25)['days_active']),\n",
    "            'conversion_rate_low': max(0.001, float(df['conversion_rate'].quantile(0.05))),\n",
    "        })\n",
    "        return tuned\n",
    "\n",
    "    THRESHOLDS = _maybe_autotune_thresholds(media_df, THRESHOLDS, auto_thresholds)\n",
    "\n",
    "    def check_domain_specialization(row):\n",
    "        cols = [c for c in media_df.columns if c.startswith('domain_') and c.endswith('_pct')]\n",
    "        for col in cols:\n",
    "            v = row.get(col, np.nan)\n",
    "            if pd.notna(v) and v >= THRESHOLDS['specialization_threshold']:\n",
    "                name = col.replace('domain_', '').replace('_pct', '')\n",
    "                return f\"{name}특화\"\n",
    "        return None\n",
    "\n",
    "    def check_size_specialization(row):\n",
    "        if pd.notna(row.get('MEGA_ratio')) and row['MEGA_ratio'] >= THRESHOLDS['mega_specialization']:\n",
    "            return \"MEGA특화\"\n",
    "        if pd.notna(row.get('LARGE_ratio')) and row['LARGE_ratio'] >= THRESHOLDS['large_specialization']:\n",
    "            return \"LARGE특화\"\n",
    "        return None\n",
    "\n",
    "    def classify_single_media(row):\n",
    "        # 1) 계약종료형 (최우선)\n",
    "        if (row['days_active'] <= 7) or (pd.notna(row['last_click_dt']) and row['last_click_dt'] < cutoff_date):\n",
    "            return \"계약종료형\"\n",
    "\n",
    "        # 2) 품질관리형 (어뷰징 의심)\n",
    "        if (row['total_clicks'] >= ABUSE_MIN_CLICKS) and (row['conversion_rate'] < THRESHOLDS['conversion_rate_low']):\n",
    "            return \"품질관리형\"\n",
    "\n",
    "        # 3) 대량처리형\n",
    "        if (row['total_ads'] >= THRESHOLDS['total_ads_large'] and\n",
    "            row['daily_avg_conversions'] >= THRESHOLDS['daily_conv_high'] and\n",
    "            row['days_active'] >= THRESHOLDS['days_active_stable']):\n",
    "            return \"대량처리형\"\n",
    "\n",
    "        # 4) 특화전문형\n",
    "        domain_spec = check_domain_specialization(row)\n",
    "        size_spec = check_size_specialization(row)\n",
    "        if (domain_spec or size_spec) and (row['days_active'] >= THRESHOLDS['days_active_new']):\n",
    "            return f\"특화전문형_{domain_spec or size_spec}\"\n",
    "\n",
    "        # 5) 신규개발형\n",
    "        if (row['days_active'] <= THRESHOLDS['days_active_new'] and\n",
    "            row['daily_avg_conversions'] >= THRESHOLDS['min_performance']):\n",
    "            return \"신규개발형\"\n",
    "\n",
    "        # 6) 안정공급형\n",
    "        if (row['total_ads'] >= THRESHOLDS['total_ads_medium'] and\n",
    "            row['daily_avg_conversions'] >= THRESHOLDS['daily_conv_medium'] and\n",
    "            row['days_active'] >= THRESHOLDS['days_active_stable']):\n",
    "            return \"안정공급형\"\n",
    "\n",
    "        # ---- Fallback: 기타 줄이기 ----\n",
    "        if reduce_misc:\n",
    "            # (a) 특화 신호만 있는 경우 → 특화전문형(후보)\n",
    "            if (domain_spec or size_spec):\n",
    "                return f\"특화전문형_{domain_spec or size_spec}(후보)\"\n",
    "            # (b) 거의 안정 조건에 근접 → 안정공급형(후보)\n",
    "            if (row['days_active'] >= max(THRESHOLDS['days_active_new'], THRESHOLDS['days_active_stable'] - 5)) and \\\n",
    "               ((row['daily_avg_conversions'] >= THRESHOLDS['min_performance']) or\n",
    "                (row['total_ads'] >= int(THRESHOLDS['total_ads_medium'] * 0.6))):\n",
    "                return \"안정공급형(후보)\"\n",
    "            # (c) 활동일이 짧으면 → 신규개발형\n",
    "            if row['days_active'] <= THRESHOLDS['days_active_new']:\n",
    "                return \"신규개발형\"\n",
    "            # (d) 남은 케이스는 관리 필요로 흡수\n",
    "            return \"관리 필요\"\n",
    "\n",
    "        return \"기타\"\n",
    "\n",
    "    media_df['classification'] = media_df.apply(classify_single_media, axis=1)\n",
    "    media_df['basic_classification'] = media_df['classification'].apply(lambda x: x.split('_')[0] if '_' in x else x)\n",
    "\n",
    "    return media_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b876b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_pf_class = classify_media_companies(media_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mda_pf_class에서 매체사 980번 빼기\n",
    "# 너무 수익 이런거 혼자 극단치 \n",
    "\n",
    "mda_pf_class = mda_pf_class[mda_pf_class['mda_idx'] != 980].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f41338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글, 오류 해결\n",
    "\n",
    "def setup_korean_font(preferred=None, verbose=True):\n",
    "    # 우선순위 높은 후보들(설치된 것 중 첫 번째를 씁니다)\n",
    "    candidates = (preferred or []) + [\n",
    "        'AppleGothic',            # macOS\n",
    "        'Malgun Gothic',          # Windows\n",
    "        'NanumGothic', 'NanumBarunGothic', 'NanumGothicCoding',\n",
    "        'Noto Sans CJK KR', 'Noto Sans KR',\n",
    "        'Arial Unicode MS'\n",
    "    ]\n",
    "    available = {f.name for f in font_manager.fontManager.ttflist}\n",
    "    for name in candidates:\n",
    "        if name in available:\n",
    "            rcParams['font.family'] = name\n",
    "            rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지\n",
    "            if verbose:\n",
    "                print(f'✅ Using font: {name}')\n",
    "            break\n",
    "    else:\n",
    "        print('⚠️ 한글 폰트가 발견되지 않았습니다. NanumGothic 또는 Noto Sans KR 설치 후 다시 실행하세요.')\n",
    "\n",
    "def silence_matplotlib_warnings():\n",
    "    # 글리프 경고/기타 matplotlib 경고 숨기기\n",
    "    warnings.filterwarnings(\"ignore\", message=r\"Glyph .* missing from font\", category=UserWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "    logging.getLogger('matplotlib').setLevel(logging.ERROR)\n",
    "\n",
    "setup_korean_font()\n",
    "silence_matplotlib_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DF = mda_pf_class.copy()  # classify_media_companies(mda_pf) 결과\n",
    "\n",
    "# 분류 라벨 정렬(보고서용 가독성)\n",
    "preferred_order = [\n",
    "    '대량처리형', '안정공급형', '안정공급형(후보)',\n",
    "    '특화전문형', '신규개발형',\n",
    "    '관리 필요', '품질관리형', '계약종료형'\n",
    "]\n",
    "classes_in_df = [c for c in preferred_order if c in DF['basic_classification'].unique()]\n",
    "DF['basic_classification'] = pd.Categorical(DF['basic_classification'], classes_in_df, ordered=True)\n",
    "\n",
    "# 사용할 지표 목록\n",
    "metrics = {\n",
    "    'expected_total_profit': '기대 수익',\n",
    "    'user_count': '유저 수',\n",
    "    'total_ads': '광고 수',\n",
    "    'daily_avg_conversions': '일평균 전환',\n",
    "    'conversion_rate': '전환율',\n",
    "    'MEGA_ratio': 'MEGA 비중(%)',\n",
    "    'LARGE_ratio': 'LARGE 비중(%)',\n",
    "    'days_active': '활동 일수'\n",
    "}\n",
    "\n",
    "# 요약 테이블(개수/평균/중앙값/합계)\n",
    "summary = DF.groupby('basic_classification').agg(\n",
    "    count=('mda_idx','count'),\n",
    "    expected_total_profit_sum=('expected_total_profit','sum'),\n",
    "    expected_total_profit_mean=('expected_total_profit','mean'),\n",
    "    expected_total_profit_median=('expected_total_profit','median'),\n",
    "    user_count_mean=('user_count','mean'),\n",
    "    user_count_median=('user_count','median'),\n",
    "    total_ads_mean=('total_ads','mean'),\n",
    "    daily_avg_conversions_mean=('daily_avg_conversions','mean'),\n",
    "    conversion_rate_mean=('conversion_rate','mean'),\n",
    "    MEGA_ratio_mean=('MEGA_ratio','mean'),\n",
    "    LARGE_ratio_mean=('LARGE_ratio','mean'),\n",
    "    days_active_mean=('days_active','mean')\n",
    ").round(2)\n",
    "display(summary)  # 노트북 환경이면 표로 보임\n",
    "\n",
    "# ---------- 헬퍼 함수 ----------\n",
    "def _bar(series, title, ylabel, rotate=0, fmt_pct=False):\n",
    "    plt.figure()\n",
    "    ax = series.plot(kind='bar')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel('분류')\n",
    "    if rotate:\n",
    "        plt.xticks(rotation=rotate)\n",
    "    if fmt_pct:\n",
    "        # y축 퍼센트 표시\n",
    "        vals = ax.get_yticks()\n",
    "        ax.set_yticklabels([f\"{v:.0f}%\" for v in vals])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _box_by_class(df, col, title, ylabel, clip_q=0.99, log=False):\n",
    "    dat = df[['basic_classification', col]].dropna().copy()\n",
    "    # 극단값 클리핑(박스플롯 스케일 안정화)\n",
    "    upper = dat[col].quantile(clip_q)\n",
    "    dat[col] = np.clip(dat[col], dat[col].min(), upper)\n",
    "    plt.figure()\n",
    "    # 하나의 축 안에서 카테고리별 박스플롯\n",
    "    groups = [g[col].values for _, g in dat.groupby('basic_classification')]\n",
    "    labels = [str(c) for c in dat['basic_classification'].cat.categories]\n",
    "    plt.boxplot(groups, labels=labels, showfliers=False)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _scatter(df, x, y, title, xlabel, ylabel, size_col=None, alpha=0.5, logx=False, logy=False):\n",
    "    dat = df[[x, y, 'basic_classification'] + ([size_col] if size_col else [])].dropna().copy()\n",
    "    plt.figure()\n",
    "    if size_col:\n",
    "        # 마커 크기 표준화\n",
    "        s = dat[size_col].replace(0, np.nan)\n",
    "        s = 50 * (s / s.quantile(0.9)).clip(0.2, 3)  # 적당한 범위로 스케일\n",
    "        plt.scatter(dat[x], dat[y], s=s, alpha=alpha)\n",
    "    else:\n",
    "        plt.scatter(dat[x], dat[y], alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if logx: plt.xscale('log')\n",
    "    if logy: plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---------- 1) 분류 분포(개수/비율) ----------\n",
    "counts = DF['basic_classification'].value_counts().reindex(classes_in_df).fillna(0)\n",
    "_bar(counts, '분류별 매체사 개수', '개수', rotate=20)\n",
    "\n",
    "pct = (counts / counts.sum() * 100).round(1)\n",
    "_bar(pct, '분류별 매체사 비율', '비율(%)', rotate=20, fmt_pct=True)\n",
    "\n",
    "# ---------- 2) 분류별 기대수익 ----------\n",
    "# 합계(시장 기여도)\n",
    "profit_sum = DF.groupby('basic_classification')['expected_total_profit'].sum().reindex(classes_in_df)\n",
    "_bar(profit_sum, '분류별 기대수익 합계', '기대수익 합계', rotate=20)\n",
    "\n",
    "# 평균/중앙값(단위 매체 기대수익)\n",
    "profit_mean = DF.groupby('basic_classification')['expected_total_profit'].mean().reindex(classes_in_df)\n",
    "_bar(profit_mean, '분류별 기대수익 평균', '평균 기대수익', rotate=20)\n",
    "\n",
    "profit_median = DF.groupby('basic_classification')['expected_total_profit'].median().reindex(classes_in_df)\n",
    "_bar(profit_median, '분류별 기대수익 중앙값', '중앙 기대수익', rotate=20)\n",
    "\n",
    "# 분포(대수 스케일 권장)\n",
    "_box_by_class(DF, 'expected_total_profit', '분류별 기대수익 분포(박스플롯)', '기대수익', clip_q=0.99, log=True)\n",
    "\n",
    "# ---------- 3) 유저 수 ----------\n",
    "user_mean = DF.groupby('basic_classification')['user_count'].mean().reindex(classes_in_df)\n",
    "_bar(user_mean, '분류별 유저 수 평균', '평균 유저 수', rotate=20)\n",
    "\n",
    "_box_by_class(DF, 'user_count', '분류별 유저 수 분포(박스플롯)', '유저 수', clip_q=0.99, log=True)\n",
    "\n",
    "# ---------- 4) 운영 볼륨(광고 수, 일평균 전환) ----------\n",
    "ads_mean = DF.groupby('basic_classification')['total_ads'].mean().reindex(classes_in_df)\n",
    "_bar(ads_mean, '분류별 광고 수 평균', '평균 광고 수', rotate=20)\n",
    "\n",
    "_box_by_class(DF, 'daily_avg_conversions', '분류별 일평균 전환 분포(박스플롯)', '일평균 전환', clip_q=0.99, log=True)\n",
    "\n",
    "# ---------- 5) 전환율 ----------\n",
    "cr_mean = DF.groupby('basic_classification')['conversion_rate'].mean().reindex(classes_in_df)\n",
    "_bar(cr_mean, '분류별 전환율 평균', '평균 전환율', rotate=20)\n",
    "\n",
    "_box_by_class(DF, 'conversion_rate', '분류별 전환율 분포(박스플롯)', '전환율', clip_q=0.99, log=False)\n",
    "\n",
    "# ---------- 6) 포맷 특성(MEGA/LARGE 비중) ----------\n",
    "mega_mean = DF.groupby('basic_classification')['MEGA_ratio'].mean().reindex(classes_in_df)\n",
    "_bar(mega_mean, '분류별 MEGA 비중 평균(%)', 'MEGA 비중(%)', rotate=20)\n",
    "\n",
    "large_mean = DF.groupby('basic_classification')['LARGE_ratio'].mean().reindex(classes_in_df)\n",
    "_bar(large_mean, '분류별 LARGE 비중 평균(%)', 'LARGE 비중(%)', rotate=20)\n",
    "\n",
    "# ---------- 7) 활동성 ----------\n",
    "days_mean = DF.groupby('basic_classification')['days_active'].mean().reindex(classes_in_df)\n",
    "_bar(days_mean, '분류별 활동 일수 평균', '평균 활동 일수', rotate=20)\n",
    "\n",
    "_box_by_class(DF, 'days_active', '분류별 활동 일수 분포(박스플롯)', '활동 일수', clip_q=0.99, log=False)\n",
    "\n",
    "# ---------- 8) 관계형 시각화(산점도) ----------\n",
    "# 기대수익 vs 유저 수 (마커 크기: 광고 수)\n",
    "_scatter(DF, 'user_count', 'expected_total_profit',\n",
    "         '기대수익 vs 유저 수 (마커 크기=광고 수)',\n",
    "         '유저 수', '기대수익', size_col='total_ads', logx=True, logy=True)\n",
    "\n",
    "# 기대수익 vs 일평균 전환\n",
    "_scatter(DF, 'daily_avg_conversions', 'expected_total_profit',\n",
    "         '기대수익 vs 일평균 전환', '일평균 전환', '기대수익', logx=True, logy=True)\n",
    "\n",
    "# 전환율 vs 기대수익\n",
    "_scatter(DF, 'conversion_rate', 'expected_total_profit',\n",
    "         '기대수익 vs 전환율', '전환율', '기대수익', logx=False, logy=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619aee07",
   "metadata": {},
   "source": [
    "# 매체사별 광고 성과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ads_performance(ads_idx, click_data, media_portfolio=None):\n",
    "    \"\"\"\n",
    "    특정 광고의 매체별 성과를 분석하는 함수\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 해당 광고의 데이터가 있는지 확인\n",
    "    ads_data = click_data[click_data['ads_idx'] == ads_idx]\n",
    "    if len(ads_data) == 0:\n",
    "        print(f\"광고 {ads_idx}에 대한 데이터가 없습니다.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 2. 기본 성과 데이터 추출\n",
    "    ads_performance = ads_data.groupby(['ads_idx', 'mda_idx']).agg({\n",
    "        'click_key': 'count',\n",
    "        'conversion': 'sum',\n",
    "        'contract_price': 'first',\n",
    "        'media_price': 'first',\n",
    "        'domain': 'first',\n",
    "        'ads_category': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 컬럼명 변경\n",
    "    ads_performance.columns = ['ads_idx', 'mda_idx', 'total_clicks', 'total_conversions', \n",
    "                              'contract_price', 'media_price', 'domain', 'ads_category']\n",
    "    \n",
    "    # 전환율 및 수익 계산\n",
    "    ads_performance['cvr'] = (\n",
    "        ads_performance['total_conversions'] / ads_performance['total_clicks']\n",
    "    ).round(4)\n",
    "    \n",
    "    ads_performance['profit_per_conversion'] = (\n",
    "        ads_performance['contract_price'] - ads_performance['media_price']\n",
    "    )\n",
    "    ads_performance['total_profit'] = (\n",
    "        ads_performance['total_conversions'] * ads_performance['profit_per_conversion']\n",
    "    )\n",
    "    \n",
    "    # 3. 날짜 범위 및 활동일 계산\n",
    "    click_data_copy = click_data.copy()\n",
    "    if not pd.api.types.is_datetime64_any_dtype(click_data_copy['click_date']):\n",
    "        click_data_copy['click_date'] = pd.to_datetime(click_data_copy['click_date'])\n",
    "    \n",
    "    ads_activity = (\n",
    "        click_data_copy.loc[click_data_copy['ads_idx'] == ads_idx]\n",
    "                      .groupby('mda_idx')['click_date']\n",
    "                      .agg(first_click='min', last_click='max')\n",
    "                      .reset_index()\n",
    "    )\n",
    "    \n",
    "    ads_activity['days_active_calc'] = (\n",
    "        (ads_activity['last_click'] - ads_activity['first_click']).dt.days + 1\n",
    "    )\n",
    "    \n",
    "    # 4. 데이터 병합\n",
    "    merged = ads_performance.merge(\n",
    "        ads_activity[['mda_idx', 'first_click', 'last_click', 'days_active_calc']],\n",
    "        on='mda_idx', how='left'\n",
    "    )\n",
    "    \n",
    "    # 5. 일평균 지표 계산\n",
    "    merged['daily_clicks'] = merged['total_clicks'] / merged['days_active_calc']\n",
    "    merged['daily_conversions'] = merged['total_conversions'] / merged['days_active_calc']\n",
    "    merged['daily_profit'] = merged['total_profit'] / merged['days_active_calc']\n",
    "    \n",
    "    # 6. 배분 그룹 분류 (데이터가 충분한 경우에만)\n",
    "    if len(merged) > 1:  # 최소 2개 이상의 매체가 있어야 중앙값 계산이 의미있음\n",
    "        profit_median = merged['daily_profit'].median()\n",
    "        conv_median = merged['daily_conversions'].median()\n",
    "        \n",
    "        merged['배분그룹'] = np.where(\n",
    "            (merged['daily_profit'] >= profit_median) & (merged['daily_conversions'] >= conv_median),\n",
    "            '잘 배분',\n",
    "            '잘못 배분'\n",
    "        )\n",
    "        # 결과 정렬\n",
    "        result = merged.sort_values(['배분그룹', 'daily_profit'], ascending=[True, False]).reset_index(drop=True)\n",
    "    else:\n",
    "        merged['배분그룹'] = '분류불가'\n",
    "        result = merged.reset_index(drop=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739664cd",
   "metadata": {},
   "source": [
    "# 매체사 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e706f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매체사 포트폴리오 각 매체사별 카테고리나 도메인 전환 비중 \n",
    "\n",
    "\n",
    "# 컬럼 이름에서 공백/특수문자 → '_' 로 바꾸는 헬퍼\n",
    "def _slug(s):\n",
    "    return re.sub(r'[^0-9A-Za-z가-힣]+', '_', str(s)).strip('_')\n",
    "\n",
    "def add_cat_domain_to_mda_pf(\n",
    "    mda_pf: pd.DataFrame,\n",
    "    clicks_df: pd.DataFrame,\n",
    "    conv_col: str = \"conversion\",\n",
    "    cat_col: str = \"ads_category\",\n",
    "    dom_col: str = \"domain\",\n",
    "    add_within_cat: bool = False,      # mda×카테고리 내부 도메인 구성비 추가 여부\n",
    "    add_within_dom: bool = False       # mda×도메인 내부 카테고리 구성비 추가 여부\n",
    "):\n",
    "    \"\"\"\n",
    "    반환: (enriched_mda_pf, new_columns)\n",
    "    - conv_cat{카테고리}_{도메인} : 해당 mda의 (카테고리×도메인) 전환수\n",
    "    - share_cat{카테고리}_{도메인}: 해당 mda 전체 전환 대비 구성비(0~1)\n",
    "    - (옵션) shareWithinCat_*, shareWithinDomain_* 도 함께 추가 가능\n",
    "    \"\"\"\n",
    "    df = clicks_df.copy()\n",
    "\n",
    "    # 전환수 정리 (0/1이 아니면 그대로 합산, 0/1이면 1 합산)\n",
    "    df[conv_col] = pd.to_numeric(df[conv_col], errors=\"coerce\").fillna(0)\n",
    "    if df[conv_col].max() <= 1:\n",
    "        df[\"conv\"] = (df[conv_col] > 0).astype(int)\n",
    "    else:\n",
    "        df[\"conv\"] = df[conv_col]\n",
    "\n",
    "    # 전환 있는 행만\n",
    "    conv = df[df[\"conv\"] > 0].copy()\n",
    "    if conv.empty:\n",
    "        enriched = mda_pf.copy()\n",
    "        return enriched, []\n",
    "\n",
    "    # mda × category × domain 전환수 집계\n",
    "    g = (conv.groupby([\"mda_idx\", cat_col, dom_col], as_index=False)[\"conv\"]\n",
    "              .sum())\n",
    "\n",
    "    # mda 전체 전환 합 → mda 대비 구성비\n",
    "    total_mda = (g.groupby(\"mda_idx\", as_index=False)[\"conv\"]\n",
    "                   .sum()\n",
    "                   .rename(columns={\"conv\":\"total_mda\"}))\n",
    "    g = g.merge(total_mda, on=\"mda_idx\", how=\"left\")\n",
    "    g[\"share_mda\"] = g[\"conv\"] / g[\"total_mda\"].replace(0, np.nan)\n",
    "    g[\"share_mda\"] = g[\"share_mda\"].fillna(0.0)\n",
    "\n",
    "    # ---- 피벗: 전환수 / mda-구성비\n",
    "    piv_cnt = (g.pivot(index=\"mda_idx\",\n",
    "                       columns=[cat_col, dom_col],\n",
    "                       values=\"conv\")\n",
    "                 .fillna(0))\n",
    "    piv_shr = (g.pivot(index=\"mda_idx\",\n",
    "                       columns=[cat_col, dom_col],\n",
    "                       values=\"share_mda\")\n",
    "                 .fillna(0.0))\n",
    "\n",
    "    # 컬럼 평탄화\n",
    "    piv_cnt.columns = [f\"conv_cat{c}_{_slug(d)}\" for c, d in piv_cnt.columns]\n",
    "    piv_shr.columns = [f\"share_cat{c}_{_slug(d)}\" for c, d in piv_shr.columns]\n",
    "\n",
    "    out = (mda_pf.merge(piv_cnt, on=\"mda_idx\", how=\"left\")\n",
    "                 .merge(piv_shr, on=\"mda_idx\", how=\"left\"))\n",
    "\n",
    "    new_cols = list(piv_cnt.columns) + list(piv_shr.columns)\n",
    "    out[new_cols] = out[new_cols].fillna(0)\n",
    "\n",
    "    # ---- (옵션) mda×카테고리 내부 도메인 구성비\n",
    "    if add_within_cat:\n",
    "        tot_cat = (g.groupby([\"mda_idx\", cat_col], as_index=False)[\"conv\"]\n",
    "                     .sum()\n",
    "                     .rename(columns={\"conv\":\"_tot_cat\"}))\n",
    "        g2 = g.merge(tot_cat, on=[\"mda_idx\", cat_col], how=\"left\")\n",
    "        g2[\"share_within_cat\"] = g2[\"conv\"] / g2[\"_tot_cat\"].replace(0, np.nan)\n",
    "        piv_wc = (g2.pivot(index=\"mda_idx\",\n",
    "                           columns=[cat_col, dom_col],\n",
    "                           values=\"share_within_cat\")\n",
    "                    .fillna(0.0))\n",
    "        piv_wc.columns = [f\"shareWithinCat_cat{c}_{_slug(d)}\" for c, d in piv_wc.columns]\n",
    "        out = out.merge(piv_wc, on=\"mda_idx\", how=\"left\")\n",
    "        out[piv_wc.columns] = out[piv_wc.columns].fillna(0.0)\n",
    "        new_cols += list(piv_wc.columns)\n",
    "\n",
    "    # ---- (옵션) mda×도메인 내부 카테고리 구성비\n",
    "    if add_within_dom:\n",
    "        tot_dom = (g.groupby([\"mda_idx\", dom_col], as_index=False)[\"conv\"]\n",
    "                     .sum()\n",
    "                     .rename(columns={\"conv\":\"_tot_dom\"}))\n",
    "        g3 = g.merge(tot_dom, on=[\"mda_idx\", dom_col], how=\"left\")\n",
    "        g3[\"share_within_domain\"] = g3[\"conv\"] / g3[\"_tot_dom\"].replace(0, np.nan)\n",
    "        piv_wd = (g3.pivot(index=\"mda_idx\",\n",
    "                           columns=[cat_col, dom_col],\n",
    "                           values=\"share_within_domain\")\n",
    "                    .fillna(0.0))\n",
    "        piv_wd.columns = [f\"shareWithinDomain_cat{c}_{_slug(d)}\" for c, d in piv_wd.columns]\n",
    "        out = out.merge(piv_wd, on=\"mda_idx\", how=\"left\")\n",
    "        out[piv_wd.columns] = out[piv_wd.columns].fillna(0.0)\n",
    "        new_cols += list(piv_wd.columns)\n",
    "\n",
    "    return out, new_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicks_df: 원본 클릭/전환 테이블 (mda_idx, ads_category, domain, conversion 포함)\n",
    "# mda_pf: 매체 프로필 테이블 (mda_idx 기준)\n",
    "\n",
    "mda_pf_enriched, added_cols = add_cat_domain_to_mda_pf(\n",
    "    mda_pf, click,\n",
    "    add_within_cat=False,     # 필요하면 True\n",
    "    add_within_dom=False      # 필요하면 True\n",
    ")\n",
    "\n",
    "print(f\"추가된 컬럼 수: {len(added_cols)}\")\n",
    "# mda_pf_enriched.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b2e57",
   "metadata": {},
   "source": [
    "## 기존 광고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe34fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 통합 셀: 유사도 추천기 (CLR + prior + power + IDF + 추가 비율 피처) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- 유틸 ---\n",
    "def _slug(s): \n",
    "    return re.sub(r'[^0-9A-Za-z가-힣]+', '_', str(s)).strip('_')\n",
    "\n",
    "def _cosine(a, B):\n",
    "    a = a.reshape(1, -1)\n",
    "    num = (B * a).sum(axis=1)\n",
    "    den = (np.sqrt((B**2).sum(axis=1)) * np.sqrt((a**2).sum()))\n",
    "    den = np.where(den == 0, 1e-12, den)\n",
    "    return (num / den).ravel()\n",
    "\n",
    "def cosine_vec(a, B):\n",
    "    return _cosine(np.asarray(a, dtype=float), np.asarray(B, dtype=float))\n",
    "\n",
    "# --- 광고 데이터로 (카테고리×도메인) 가중치 + prior 스무딩 ---\n",
    "def make_ad_pair_weights_from_ad_df(\n",
    "    ad_df, cat_col='ads_category', dom_col='domain',\n",
    "    conv_col='total_conversions', power=1.0, min_frac=0.0,\n",
    "    prior_mix=0.0, prior_bg=None\n",
    "):\n",
    "    \"\"\"\n",
    "    (카테×도메인) 전환 분포 -> share_cat{c}_{slug} 가중치 dict\n",
    "    power<1: 퍼짐, >1: 집중 / prior_mix: 배경분포 섞기\n",
    "    \"\"\"\n",
    "    t = ad_df.copy()\n",
    "    t[conv_col] = pd.to_numeric(t[conv_col], errors='coerce').fillna(0.0)\n",
    "    g = (t.groupby([cat_col, dom_col])[conv_col].sum()\n",
    "           .rename('conv').reset_index())\n",
    "    tot = g['conv'].sum()\n",
    "    if tot <= 0:\n",
    "        return {}\n",
    "    g['frac'] = g['conv'] / tot\n",
    "    if min_frac > 0:\n",
    "        g = g[g['frac'] >= min_frac].copy()\n",
    "    g['w'] = (g['frac'] ** power)\n",
    "    s = g['w'].sum()\n",
    "    if s > 0:\n",
    "        g['w'] = g['w'] / s\n",
    "    g['key'] = [f\"share_cat{int(c)}_{_slug(d)}\" for c,d in g[[cat_col, dom_col]].itertuples(index=False)]\n",
    "    w = dict(zip(g['key'], g['w']))\n",
    "\n",
    "    # prior 스무딩\n",
    "    if prior_mix and prior_mix > 0:\n",
    "        if (prior_bg is None) or (len(prior_bg) == 0):\n",
    "            prior_bg = {k: 1.0/len(w) for k in w.keys()}\n",
    "        keys = set(w) | set(prior_bg)\n",
    "        out = {}\n",
    "        for k in keys:\n",
    "            pw = w.get(k, 0.0)\n",
    "            q  = prior_bg.get(k, 0.0)\n",
    "            out[k] = (1.0 - prior_mix) * pw + prior_mix * q\n",
    "        Z = sum(out.values()) or 1.0\n",
    "        w = {k: v/Z for k,v in out.items()}\n",
    "    return w\n",
    "\n",
    "# --- 구성비 CLR 변환 ---\n",
    "def _clr_block(df_block, eps=1e-6):\n",
    "    Z = df_block.clip(lower=eps)\n",
    "    g = np.exp(np.log(Z).mean(axis=1))\n",
    "    return np.log(Z.div(g, axis=0))\n",
    "\n",
    "# --- 피처 행렬 (share + 볼륨 + 각종 비율 + CLR + 가중 + z-score) ---\n",
    "def build_feature_matrix_plus(\n",
    "    mda_pf,\n",
    "    share_cols,                 \n",
    "    volume_cols=None,           \n",
    "    size_ratio_cols=None,       \n",
    "    os_ratio_cols=None,         \n",
    "    category_ratio_cols=None,   \n",
    "    domain_ratio_cols=None,     \n",
    "    use_clr=True,               \n",
    "    col_weights=None,           \n",
    "    zscore=True\n",
    "):\n",
    "    volume_cols         = list(volume_cols or [])\n",
    "    size_ratio_cols     = list(size_ratio_cols or [])\n",
    "    os_ratio_cols       = list(os_ratio_cols or [])\n",
    "    category_ratio_cols = list(category_ratio_cols or [])\n",
    "    domain_ratio_cols   = list(domain_ratio_cols or [])\n",
    "\n",
    "    all_cols = (list(share_cols) + volume_cols + size_ratio_cols +\n",
    "                os_ratio_cols + category_ratio_cols + domain_ratio_cols)\n",
    "\n",
    "    X = mda_pf.set_index('mda_idx')[all_cols].astype(float).copy()\n",
    "\n",
    "    # 결측\n",
    "    X[volume_cols] = X[volume_cols].fillna(0.0)\n",
    "    X[size_ratio_cols + os_ratio_cols + category_ratio_cols + domain_ratio_cols + share_cols] = \\\n",
    "        X[size_ratio_cols + os_ratio_cols + category_ratio_cols + domain_ratio_cols + share_cols].fillna(0.0)\n",
    "\n",
    "    # 볼륨: log1p\n",
    "    if volume_cols:\n",
    "        X[volume_cols] = np.log1p(X[volume_cols])\n",
    "\n",
    "    # 비율: CLR\n",
    "    if use_clr:\n",
    "        if size_ratio_cols:\n",
    "            X[size_ratio_cols] = _clr_block(X[size_ratio_cols])\n",
    "        if os_ratio_cols:\n",
    "            X[os_ratio_cols] = _clr_block(X[os_ratio_cols])\n",
    "        if category_ratio_cols:\n",
    "            X[category_ratio_cols] = _clr_block(X[category_ratio_cols])\n",
    "        if domain_ratio_cols:\n",
    "            X[domain_ratio_cols] = _clr_block(X[domain_ratio_cols])\n",
    "\n",
    "    # 열 가중\n",
    "    if col_weights:\n",
    "        w = pd.Series({c: col_weights.get(c, 1.0) for c in all_cols}, index=all_cols, dtype=float)\n",
    "        X = X.mul(w, axis=1)\n",
    "\n",
    "    # 표준화\n",
    "    if zscore:\n",
    "        X = (X - X.mean()) / (X.std() + 1e-9)\n",
    "\n",
    "    return X, all_cols\n",
    "\n",
    "# --- 메인 추천 ---\n",
    "def recommend_with_weighted_similarity(\n",
    "    ad_df,\n",
    "    mda_pf,\n",
    "    top_anchor_by='total_conversions',\n",
    "    n_anchor=5,\n",
    "    topN=20,\n",
    "    weight_power=0.5,\n",
    "    min_pair_frac=0.0,\n",
    "    top_weight_feats=None,\n",
    "    exclude_classes=('계약종료형','품질관리형'),\n",
    "    min_days_active=7,\n",
    "    blend_pred_table=None,\n",
    "    blend_ad_id=None,\n",
    "    blend_alpha=0.7,\n",
    "    sort_by=\"final\",\n",
    "\n",
    "    # 피처 세트(있으면 자동 사용)\n",
    "    volume_cols=(\"user_count\",\"total_clicks\",\"total_conversions\",\"daily_avg_conversions\",\"total_ads\"),\n",
    "    size_ratio_cols=(\"MEGA_ratio\",\"LARGE_ratio\",\"MEDIUM_ratio\",\"SMALL_ratio\"),\n",
    "    os_ratio_cols=(\"ads_os_type_1_pct\",\"ads_os_type_2_pct\",\"ads_os_type_3_pct\",\"ads_os_type_7_pct\"),\n",
    "    category_ratio_cols=(\"ads_category_0_pct\",\"ads_category_1_pct\",\"ads_category_2_pct\",\"ads_category_3_pct\",\n",
    "                         \"ads_category_4_pct\",\"ads_category_5_pct\",\"ads_category_6_pct\",\"ads_category_7_pct\",\n",
    "                         \"ads_category_8_pct\",\"ads_category_10_pct\",\"ads_category_11_pct\",\"ads_category_13_pct\"),\n",
    "    domain_ratio_cols=(\"domain_게임_pct\",\"domain_교육_pct\",\"domain_금융_pct\",\"domain_기타_pct\",\"domain_미디어/컨텐츠_pct\",\n",
    "                       \"domain_뷰티_pct\",\"domain_비영리/공공_pct\",\"domain_생활_pct\",\"domain_식당/카페_pct\",\"domain_식음료_pct\",\n",
    "                       \"domain_운동/스포츠_pct\",\"domain_운세_pct\",\"domain_의료/건강_pct\",\"domain_채용_pct\",\"domain_커머스_pct\"),\n",
    "\n",
    "    use_clr=True,\n",
    "    extra_col_weights=None,\n",
    "\n",
    "    # 안정화 옵션\n",
    "    prior_mix=0.2,\n",
    "    prior_from=\"mda_mean\",   # \"mda_mean\" | \"uniform\" | \"none\"\n",
    "    prior_bg_dict=None,\n",
    "    use_idf=False,\n",
    "    idf_smooth=1.0,\n",
    "    min_similarity=None\n",
    "):\n",
    "    # share 피처\n",
    "    share_cols = [c for c in mda_pf.columns if c.startswith('share_cat')]\n",
    "    if not share_cols:\n",
    "        raise ValueError(\"mda_pf에 share_cat* 컬럼이 없습니다. 먼저 enrichment를 수행하세요.\")\n",
    "\n",
    "    # 존재하는 컬럼만 사용\n",
    "    def _keep_exist(cols): return [c for c in cols if c in mda_pf.columns]\n",
    "    volume_cols         = _keep_exist(volume_cols)\n",
    "    size_ratio_cols     = _keep_exist(size_ratio_cols)\n",
    "    os_ratio_cols       = _keep_exist(os_ratio_cols)\n",
    "    category_ratio_cols = _keep_exist(category_ratio_cols)\n",
    "    domain_ratio_cols   = _keep_exist(domain_ratio_cols)\n",
    "\n",
    "    # prior 배경 분포\n",
    "    prior_bg = None\n",
    "    if prior_bg_dict is not None:\n",
    "        prior_bg = dict(prior_bg_dict)\n",
    "    elif prior_from == \"mda_mean\":\n",
    "        avg = mda_pf[share_cols].fillna(0.0).mean(axis=0)\n",
    "        s = avg.sum()\n",
    "        if s > 0:\n",
    "            prior_bg = (avg / s).to_dict()\n",
    "    elif prior_from == \"uniform\":\n",
    "        prior_bg = {c: 1.0/len(share_cols) for c in share_cols}\n",
    "\n",
    "    # 가중치(광고 분포) 생성\n",
    "    col_w = make_ad_pair_weights_from_ad_df(\n",
    "        ad_df, power=weight_power, min_frac=min_pair_frac,\n",
    "        prior_mix=prior_mix if prior_mix else 0.0,\n",
    "        prior_bg=prior_bg\n",
    "    )\n",
    "    if top_weight_feats:\n",
    "        top_keys = set(pd.Series(col_w).sort_values(ascending=False).head(top_weight_feats).index)\n",
    "        col_w = {k: (v if k in top_keys else 0.0) for k,v in col_w.items()}\n",
    "\n",
    "    # IDF 보정(옵션)\n",
    "    if use_idf:\n",
    "        df_share = (mda_pf[share_cols].fillna(0) != 0).sum(axis=0)\n",
    "        N = len(mda_pf)\n",
    "        idf = np.log((N + 1.0) / (df_share + idf_smooth))\n",
    "        idf = idf / (idf.mean() + 1e-12)\n",
    "        for k in list(col_w.keys()):\n",
    "            if k in idf.index:\n",
    "                col_w[k] *= float(idf[k])\n",
    "\n",
    "    if extra_col_weights:\n",
    "        col_w.update(extra_col_weights)\n",
    "\n",
    "    # 피처 행렬\n",
    "    X, all_feat_cols = build_feature_matrix_plus(\n",
    "        mda_pf,\n",
    "        share_cols=share_cols,\n",
    "        volume_cols=volume_cols,\n",
    "        size_ratio_cols=size_ratio_cols,\n",
    "        os_ratio_cols=os_ratio_cols,\n",
    "        category_ratio_cols=category_ratio_cols,\n",
    "        domain_ratio_cols=domain_ratio_cols,\n",
    "        use_clr=use_clr,\n",
    "        col_weights=col_w,\n",
    "        zscore=True\n",
    "    )\n",
    "\n",
    "    # 앵커/센트로이드\n",
    "    used = set(ad_df['mda_idx'].astype(int))\n",
    "    anchors = (ad_df.sort_values(top_anchor_by, ascending=False)\n",
    "                   .drop_duplicates('mda_idx')\n",
    "                   .head(n_anchor)['mda_idx']\n",
    "                   .astype(int).tolist())\n",
    "    anchors = [m for m in anchors if m in X.index]\n",
    "    if not anchors:\n",
    "        raise ValueError(\"anchor가 없습니다. ad_df에 상위 매체가 있는지 확인하세요.\")\n",
    "    centroid = X.loc[anchors].mean(axis=0).values\n",
    "\n",
    "    # 후보 & 필터\n",
    "    cand = mda_pf[~mda_pf['mda_idx'].isin(used)].copy()\n",
    "    if 'basic_classification' in cand.columns and exclude_classes:\n",
    "        cand = cand[~cand['basic_classification'].isin(exclude_classes)]\n",
    "    if 'days_active' in cand.columns:\n",
    "        cand = cand[cand['days_active'] >= min_days_active]\n",
    "    if cand.empty:\n",
    "        return pd.DataFrame(columns=['mda_idx','similarity']), anchors, all_feat_cols, col_w\n",
    "\n",
    "    # 유사도\n",
    "    B = X.loc[cand['mda_idx']].values\n",
    "    cand['similarity'] = cosine_vec(centroid, B)\n",
    "    if (min_similarity is not None):\n",
    "        cand = cand[cand['similarity'] >= float(min_similarity)]\n",
    "        if cand.empty:\n",
    "            return pd.DataFrame(columns=['mda_idx','similarity']), anchors, all_feat_cols, col_w\n",
    "\n",
    "    # 예측 블렌딩(옵션)\n",
    "    has_pred = (blend_pred_table is not None) and (blend_ad_id is not None)\n",
    "    if has_pred:\n",
    "        pt = blend_pred_table[blend_pred_table['ads_idx']==blend_ad_id][['mda_idx','pred_turn']].copy()\n",
    "        cand = cand.merge(pt, on='mda_idx', how='left')\n",
    "        cand['pred_turn'] = cand['pred_turn'].fillna(0.0)\n",
    "        maxv = cand['pred_turn'].max()\n",
    "        cand['pred_norm'] = cand['pred_turn'] / (maxv + 1e-9)\n",
    "        cand['final_score'] = blend_alpha*cand['similarity'] + (1.0-blend_alpha)*cand['pred_norm']\n",
    "\n",
    "    # 정렬\n",
    "    if sort_by == \"pred\" and has_pred:\n",
    "        sort_key = \"pred_turn\"\n",
    "    elif sort_by == \"sim\":\n",
    "        sort_key = \"similarity\"\n",
    "    else:\n",
    "        sort_key = \"final_score\" if has_pred else \"similarity\"\n",
    "\n",
    "    keep = [c for c in [\n",
    "        'mda_idx','similarity','final_score','pred_turn','pred_norm',\n",
    "        'basic_classification','days_active','conversion_rate',\n",
    "        'expected_total_profit','total_ads'\n",
    "    ] if c in cand.columns]\n",
    "    out = cand[keep].sort_values(sort_key, ascending=False).head(topN).reset_index(drop=True)\n",
    "    return out, anchors, all_feat_cols, col_w\n",
    "# === /통합 셀 끝 ===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, anchors, feats, w = recommend_with_weighted_similarity(\n",
    "    ad_df=ads_9935_pf,\n",
    "    mda_pf=mda_pf_enriched,\n",
    "    use_clr=True,          # 비율 전부 CLR\n",
    "    weight_power=0.5,      # 루트 가중\n",
    "    prior_mix=0.2,         # 배경 분포 섞기\n",
    "    prior_from=\"mda_mean\", # mda 평균 분포\n",
    "    n_anchor=5\n",
    ")\n",
    "display(out.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d232e9",
   "metadata": {},
   "source": [
    "## 신규 광고 유사도, 전환율예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 신규(가상) 광고 → 유사 광고 코호트 기반 매체별 CVR/전환수 예측 (원샷 셀)\n",
    "# ==============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------- 파일 경로 -----------------\n",
    "PERF_CSV = \"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/수정_시간별적립보고서(최종).csv\"   # 시간별 집계(또는 로그)\n",
    "META_CSV = \"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/광고도메인리스트.csv\"             # 기존 광고 메타(ads_idx 존재)\n",
    "NEW_ADS_CSV = \"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/신규가상광고.csv\"                                                    # 신규 가상광고 목록\n",
    "\n",
    "# ----------------- 하이퍼파라미터 -----------------\n",
    "L_DAYS = 30                 # 예측에 사용할 과거 창 길이\n",
    "H_DAYS = 30                 # 시나리오B(향후 H일) 클릭/전환 예측 길이\n",
    "K = 10                      # 유사 광고 코호트 크기\n",
    "BETA_SIM = 1.0              # 유사도 가중 지수 (cos sim^beta)\n",
    "ALPHA_PRIOR = 2.0           # 베타-바이노믹 스무딩 alpha\n",
    "BETA_PRIOR = 120.0          # 베타-바이노믹 스무딩 beta\n",
    "BLEND_KAPPA = 15.0          # 블렌딩 전환: eff/(eff+kappa)\n",
    "DOMAIN_WEIGHT = 1.0         # 도메인 가중치(영향 키우려면 2~3)\n",
    "RESTRICT_SAME_DOMAIN = False# True면 같은 도메인 후보만 코호트로\n",
    "DROP_RARE_MIN_ADS = 3       # 희귀 원-핫 열 제거(3개 미만 광고에서만 등장)\n",
    "\n",
    "CAT_COLS = [\"domain\", \"ads_category\", \"ads_os_type\", \"ads_type\", \"ads_rejoin_type\"]\n",
    "PRICE_CANDIDATES = (\"ads_media_price\", \"media_price\", \"contract_price\")\n",
    "\n",
    "# ----------------- 작은 유틸 -----------------\n",
    "def _norm_meta(df):\n",
    "    df = df.copy()\n",
    "    for c in CAT_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def _pick_date_col(df):\n",
    "    for c in [\"rpt_time_date\",\"click_day\",\"click_date\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(\"날짜 컬럼(rpt_time_date / click_day / click_date) 없음\")\n",
    "\n",
    "def _clicks_convs_cols(df):\n",
    "    clicks = None; convs = None\n",
    "    if \"rpt_time_clk\" in df.columns: clicks = \"rpt_time_clk\"\n",
    "    elif \"clicks\" in df.columns:     clicks = \"clicks\"\n",
    "    elif \"click_key\" in df.columns:  clicks = None           # 로그면 size()로 산출\n",
    "\n",
    "    if \"rpt_time_turn\" in df.columns: convs = \"rpt_time_turn\"\n",
    "    elif \"conversions\" in df.columns: convs = \"conversions\"\n",
    "    elif \"conversion\" in df.columns:  convs = \"conversion\"\n",
    "    return clicks, convs\n",
    "\n",
    "def _z(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    mu, sd = np.nanmean(s), np.nanstd(s)\n",
    "    sd = 1.0 if (sd is None or sd == 0 or np.isnan(sd)) else sd\n",
    "    return (s - mu) / sd, float(mu), float(sd)\n",
    "\n",
    "# ----------------- 1) 기존 광고로 피처 공간 학습 -----------------\n",
    "def build_feature_space(ad_meta, drop_rare_min_ads=3, domain_weight=1.0):\n",
    "    meta = _norm_meta(ad_meta).drop_duplicates(\"ads_idx\").copy()\n",
    "\n",
    "    X_list = []\n",
    "    group_cols = {}\n",
    "\n",
    "    # (a) 범주형 원-핫\n",
    "    for c in CAT_COLS:\n",
    "        if c in meta.columns:\n",
    "            one = pd.get_dummies(meta[c].astype(str), prefix=c, dtype=float)\n",
    "            if c == \"domain\" and domain_weight != 1.0:\n",
    "                one = one * float(domain_weight)\n",
    "            X_list.append(one)\n",
    "            group_cols[c] = list(one.columns)\n",
    "\n",
    "    # (b) 수치형(가격) - 후보 중 존재하는 첫 컬럼 사용\n",
    "    price_col = next((c for c in PRICE_CANDIDATES if c in meta.columns), None)\n",
    "    price_mu = price_sd = None\n",
    "    if price_col is not None:\n",
    "        price_log = np.log1p(pd.to_numeric(meta[price_col], errors=\"coerce\"))\n",
    "        price_z, price_mu, price_sd = _z(price_log)\n",
    "        X_list.append(price_z.to_frame(\"price_z\"))\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"ad_meta에서 만들 수 있는 피처가 없습니다.\")\n",
    "\n",
    "    X = pd.concat(X_list, axis=1).fillna(0.0)\n",
    "    # 희귀 원-핫 열 제거\n",
    "    if drop_rare_min_ads and drop_rare_min_ads > 1:\n",
    "        nz = (X != 0).sum(0)\n",
    "        keep = nz[nz >= float(drop_rare_min_ads)].index\n",
    "        X = X[keep]\n",
    "        # 그룹 열 목록 갱신\n",
    "        for g in list(group_cols.keys()):\n",
    "            group_cols[g] = [col for col in group_cols[g] if col in X.columns]\n",
    "\n",
    "    # z-score (열 단위)\n",
    "    mu = X.mean()\n",
    "    sd = X.std(ddof=0).replace(0, 1.0)\n",
    "    A_z = (X - mu) / (sd + 1e-9)\n",
    "    A_z.index = meta[\"ads_idx\"].astype(int).values\n",
    "\n",
    "    store = dict(\n",
    "        A_z=A_z.astype(np.float32),\n",
    "        mu=mu.astype(np.float32), sd=sd.astype(np.float32),\n",
    "        cols=A_z.columns.tolist(),\n",
    "        group_cols=group_cols,\n",
    "        price_col=price_col,\n",
    "        price_mu=price_mu, price_sd=price_sd,\n",
    "        meta_small=meta[[\"ads_idx\"] + [c for c in CAT_COLS if c in meta.columns]]\n",
    "    )\n",
    "    return store\n",
    "\n",
    "# ----------------- 2) 신규 광고 1건 인코딩(기존 공간에 맞춤) -----------------\n",
    "def encode_new_ad_row(row, store):\n",
    "    cols = store[\"cols\"]\n",
    "    x = pd.Series(0.0, index=cols, dtype=float)\n",
    "\n",
    "    # 범주형: 기존에 있던 열만 1로 세움(새로운 카테고리는 정보 없음 → 0)\n",
    "    for c in CAT_COLS:\n",
    "        if c in row.index:\n",
    "            val = str(row[c]).strip()\n",
    "            one_col = f\"{c}_{val}\"\n",
    "            if one_col in x.index:\n",
    "                x[one_col] = 1.0\n",
    "\n",
    "    # 가격: log1p 후 기존 z스케일 사용\n",
    "    pcol = store[\"price_col\"]\n",
    "    if pcol and pcol in row.index:\n",
    "        val = pd.to_numeric(row[pcol], errors=\"coerce\")\n",
    "        if pd.notnull(val):\n",
    "            z = (np.log1p(val) - store[\"price_mu\"]) / (store[\"price_sd\"] + 1e-9)\n",
    "            if \"price_z\" in x.index:\n",
    "                x[\"price_z\"] = float(z)\n",
    "\n",
    "    # L2 정규화용 벡터 반환\n",
    "    a = x.values.astype(np.float32)\n",
    "    a = a / (np.linalg.norm(a) + 1e-12)\n",
    "    return x, a\n",
    "\n",
    "# ----------------- 3) 신규 광고 → 유사 광고 코호트 추출 -----------------\n",
    "def cohort_for_new_ad(row, store, K=50, beta=BETA_SIM, restrict_same_domain=False):\n",
    "    A = store[\"A_z\"]\n",
    "    # 후보 제한(같은 도메인)\n",
    "    cand = A\n",
    "    if restrict_same_domain and \"domain\" in row.index and \"domain\" in store[\"meta_small\"].columns:\n",
    "        dom = str(row[\"domain\"]).strip()\n",
    "        ok_ids = store[\"meta_small\"].loc[\n",
    "            store[\"meta_small\"][\"domain\"].astype(str).str.strip() == dom, \"ads_idx\"\n",
    "        ].astype(int)\n",
    "        cand = A.loc[A.index.intersection(ok_ids)]\n",
    "\n",
    "    # 인코딩\n",
    "    x, a = encode_new_ad_row(row, store)\n",
    "    M = cand.values\n",
    "    norms = np.sqrt((M*M).sum(1)) + 1e-12\n",
    "    sims = (M @ a) / norms\n",
    "\n",
    "    if len(sims) == 0:\n",
    "        return pd.DataFrame(columns=[\"weight\",\"sim\"])\n",
    "\n",
    "    k = min(K, len(sims))\n",
    "    top = np.argpartition(-sims, k-1)[:k]\n",
    "    top = top[np.argsort(-sims[top])]\n",
    "\n",
    "    sim_vals = sims[top]\n",
    "    w = np.power(np.clip(sim_vals, 0, 1), beta); w = w / (w.sum() + 1e-12)\n",
    "\n",
    "    out = pd.DataFrame({\"ads_idx\": cand.index.values[top].astype(int),\n",
    "                        \"sim\": sim_vals, \"weight\": w})\n",
    "    out = out.set_index(\"ads_idx\")\n",
    "    return out\n",
    "\n",
    "# ----------------- 4) 코호트 기반 매체사 CVR/전환수 예측 -----------------\n",
    "def predict_media_from_cohort(perf_df, ad_meta_df, cohort_df, new_row,\n",
    "                              L_days=30, H_days=30,\n",
    "                              alpha_prior=ALPHA_PRIOR, beta_prior=BETA_PRIOR,\n",
    "                              blend_kappa=BLEND_KAPPA):\n",
    "    if cohort_df.empty:\n",
    "        return pd.DataFrame(), {\"window_end\": None, \"L_days\": L_days, \"H_days\": H_days}\n",
    "\n",
    "    perf = perf_df.copy()\n",
    "    date_col = _pick_date_col(perf)\n",
    "    perf[date_col] = pd.to_datetime(perf[date_col])\n",
    "    wend = perf[date_col].max().normalize()\n",
    "    start = wend - pd.Timedelta(days=L_days-1)\n",
    "    hist = perf[(perf[date_col]>=start) & (perf[date_col]<=wend)].copy()\n",
    "\n",
    "    clk_col, cv_col = _clicks_convs_cols(hist)\n",
    "\n",
    "    # ads_category를 히스토리에 붙임(매체×카테 베이스라인용)\n",
    "    if \"ads_category\" in ad_meta_df.columns and \"ads_category\" not in hist.columns:\n",
    "        cat_map = ad_meta_df.drop_duplicates(\"ads_idx\").set_index(\"ads_idx\")[\"ads_category\"]\n",
    "        hist = hist.merge(cat_map.rename(\"ads_category\"), left_on=\"ads_idx\", right_index=True, how=\"left\")\n",
    "\n",
    "    # 코호트 가중 집계\n",
    "    sub = hist[hist[\"ads_idx\"].isin(cohort_df.index)].copy()\n",
    "    if sub.empty:\n",
    "        return pd.DataFrame(), {\"window_end\": str(wend.date()), \"L_days\": L_days, \"H_days\": H_days}\n",
    "\n",
    "    if clk_col is None:\n",
    "        g = sub.groupby([\"ads_idx\",\"mda_idx\"]).agg(\n",
    "            clicks=(\"ads_idx\",\"size\"), convs=(\"conversion\",\"sum\")\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        g = sub.groupby([\"ads_idx\",\"mda_idx\"]).agg(\n",
    "            clicks=(clk_col,\"sum\"), convs=(cv_col,\"sum\")\n",
    "        ).reset_index()\n",
    "\n",
    "    w_map = cohort_df[\"weight\"].to_dict()\n",
    "    g[\"w\"] = g[\"ads_idx\"].map(w_map).fillna(0.0)\n",
    "    g[\"w_clicks\"] = g[\"w\"] * g[\"clicks\"]\n",
    "    g[\"w_convs\"]  = g[\"w\"] * g[\"convs\"]\n",
    "\n",
    "    agg = g.groupby(\"mda_idx\").agg(\n",
    "        cohort_eff_clicks=(\"w_clicks\",\"sum\"),\n",
    "        cohort_eff_convs=(\"w_convs\",\"sum\"),\n",
    "        coverage_ads=(\"ads_idx\",\"nunique\")\n",
    "    )\n",
    "\n",
    "    # 베이스라인 (매체 전체)\n",
    "    if clk_col is None:\n",
    "        base_m = hist.groupby(\"mda_idx\").agg(\n",
    "            clicks=(\"ads_idx\",\"size\"), convs=(\"conversion\",\"sum\")\n",
    "        )\n",
    "    else:\n",
    "        base_m = hist.groupby(\"mda_idx\").agg(\n",
    "            clicks=(clk_col,\"sum\"), convs=(cv_col,\"sum\")\n",
    "        )\n",
    "    base_m[\"cvr_m\"] = (base_m[\"convs\"] + alpha_prior) / (base_m[\"clicks\"] + alpha_prior + beta_prior)\n",
    "\n",
    "    # 베이스라인 (매체×카테고리: 신규 광고의 카테고리 사용)\n",
    "    tcat = None\n",
    "    if \"ads_category\" in new_row.index:\n",
    "        try:\n",
    "            tcat = int(pd.to_numeric(new_row[\"ads_category\"], errors=\"coerce\"))\n",
    "        except Exception:\n",
    "            tcat = None\n",
    "\n",
    "    base_mc = pd.DataFrame()\n",
    "    if (tcat is not None) and (\"ads_category\" in hist.columns):\n",
    "        subcat = hist[hist[\"ads_category\"]==tcat]\n",
    "        if not subcat.empty:\n",
    "            if clk_col is None:\n",
    "                base_mc = subcat.groupby(\"mda_idx\").agg(\n",
    "                    clicks=(\"ads_idx\",\"size\"), convs=(\"conversion\",\"sum\")\n",
    "                )\n",
    "            else:\n",
    "                base_mc = subcat.groupby(\"mda_idx\").agg(\n",
    "                    clicks=(clk_col,\"sum\"), convs=(cv_col,\"sum\")\n",
    "                )\n",
    "            base_mc[\"cvr_mc\"] = (base_mc[\"convs\"] + alpha_prior) / (base_mc[\"clicks\"] + alpha_prior + beta_prior)\n",
    "\n",
    "    out = agg.join(base_m[[\"cvr_m\"]], how=\"left\").join(base_mc[[\"cvr_mc\"]], how=\"left\").fillna({\"cvr_m\":0.0})\n",
    "    out[\"cvr_cohort\"] = (out[\"cohort_eff_convs\"] + alpha_prior) / (out[\"cohort_eff_clicks\"] + alpha_prior + beta_prior)\n",
    "    base = out[\"cvr_mc\"].fillna(out[\"cvr_m\"])\n",
    "    eff = out[\"cohort_eff_clicks\"]\n",
    "    w1 = eff / (eff + float(blend_kappa))\n",
    "    out[\"pred_cvr\"] = w1 * out[\"cvr_cohort\"] + (1.0 - w1) * base\n",
    "    out[\"per_1000_clicks_conv\"] = out[\"pred_cvr\"] * 1000.0\n",
    "\n",
    "    # 시나리오: 코호트 일평균 클릭 × H_days\n",
    "    if clk_col is None:\n",
    "        per_day = (sub.groupby([\"mda_idx\", sub[date_col].dt.normalize()])[\"ads_idx\"]\n",
    "                   .size().rename(\"clk\").reset_index())\n",
    "    else:\n",
    "        per_day = (sub.groupby([\"mda_idx\", sub[date_col].dt.normalize()])[clk_col]\n",
    "                   .sum().rename(\"clk\").reset_index())\n",
    "    daily = per_day.groupby(\"mda_idx\")[\"clk\"].mean()\n",
    "    out[\"scenarioB_clicks\"] = daily.reindex(out.index).fillna(0.0).values * float(H_DAYS)\n",
    "    out[\"scenarioB_conv\"]   = out[\"pred_cvr\"] * out[\"scenarioB_clicks\"]\n",
    "\n",
    "    out = out.reset_index().sort_values(\"per_1000_clicks_conv\", ascending=False).reset_index(drop=True)\n",
    "    info = {\"window_end\": str(wend.date()), \"L_days\": L_DAYS, \"H_days\": H_DAYS}\n",
    "    return out, info\n",
    "\n",
    "# ----------------- 5) 배치 실행: 신규 광고 목록 전체 처리 -----------------\n",
    "def run_new_ads_batch(new_ads_df, ad_meta_df, perf_df,\n",
    "                      topN_media=20, show_first_n=1):\n",
    "    store = build_feature_space(ad_meta_df, drop_rare_min_ads=DROP_RARE_MIN_ADS,\n",
    "                                domain_weight=DOMAIN_WEIGHT)\n",
    "\n",
    "    results = {}  # key: new_ad_key → (pred_df, cohort_df, info)\n",
    "    # 신규 광고의 key 컬럼 결정(ads_idx가 없으면 행번호 사용)\n",
    "    key_col = \"ads_idx\" if \"ads_idx\" in new_ads_df.columns else None\n",
    "\n",
    "    for i, row in new_ads_df.iterrows():\n",
    "        new_key = int(row[key_col]) if key_col else int(i)\n",
    "        cohort = cohort_for_new_ad(row, store, K=K, beta=BETA_SIM,\n",
    "                                   restrict_same_domain=RESTRICT_SAME_DOMAIN)\n",
    "        pred, info = predict_media_from_cohort(perf_df, ad_meta_df, cohort, row,\n",
    "                                               L_days=L_DAYS, H_days=H_DAYS,\n",
    "                                               alpha_prior=ALPHA_PRIOR, beta_prior=BETA_PRIOR,\n",
    "                                               blend_kappa=BLEND_KAPPA)\n",
    "        results[new_key] = (pred, cohort, info)\n",
    "\n",
    "    # 미리보기\n",
    "    shown = 0\n",
    "    for k, (pred, cohort, info) in results.items():\n",
    "        print(f\"\\n=== 신규광고 {k} : window_end={info['window_end']}, L_days={info['L_days']} ===\")\n",
    "        if not cohort.empty:\n",
    "            disp = cohort.reset_index().rename(columns={\"index\":\"ads_idx\"})[[\"ads_idx\",\"sim\",\"weight\"]].head(10)\n",
    "            display(disp.style.format({\"sim\":\"{:.3f}\",\"weight\":\"{:.3f}\"}))\n",
    "        else:\n",
    "            print(\"코호트가 비어 있습니다.\")\n",
    "\n",
    "        if not pred.empty:\n",
    "            cols = [\"mda_idx\",\"pred_cvr\",\"per_1000_clicks_conv\",\n",
    "                    \"cohort_eff_clicks\",\"coverage_ads\",\n",
    "                    \"cvr_m\",\"cvr_mc\",\"cvr_cohort\",\n",
    "                    \"scenarioB_clicks\",\"scenarioB_conv\"]\n",
    "            display(pred.head(topN_media)[[c for c in cols if c in pred.columns]]\n",
    "                    .style.format({\"pred_cvr\":\"{:.6f}\",\"per_1000_clicks_conv\":\"{:.3f}\",\n",
    "                                   \"cvr_m\":\"{:.6f}\",\"cvr_mc\":\"{:.6f}\",\"cvr_cohort\":\"{:.6f}\",\n",
    "                                   \"scenarioB_clicks\":\"{:.3f}\",\"scenarioB_conv\":\"{:.3f}\"}))\n",
    "        else:\n",
    "            print(\"히스토리 구간에서 코호트 데이터가 없습니다.\")\n",
    "        shown += 1\n",
    "        if shown >= show_first_n:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "# ================== 실행 ==================\n",
    "# 1) 데이터 로드(네 파일 스키마에 맞춰 자동 인식)\n",
    "# perf_df = pd.read_csv(PERF_CSV, encoding=\"utf-8-sig\")\n",
    "# ad_meta_df = pd.read_csv(META_CSV, encoding=\"utf-8-sig\")\n",
    "# new_ads_df = pd.read_csv(NEW_ADS_CSV, encoding=\"utf-8-sig\")\n",
    "\n",
    "# # 2) 배치 실행 (상위 1개 신규광고만 미리보기)\n",
    "# results = run_new_ads_batch(new_ads_df, ad_meta_df, perf_df,\n",
    "#                             topN_media=20, show_first_n=1)\n",
    "\n",
    "# 3) 특정 신규광고 결과 꺼내쓰기 예:\n",
    "# new_id = list(results.keys())[0]\n",
    "# pred_df, cohort_df, info = results[new_id]\n",
    "# display(pred_df.head(30))\n",
    "# display(cohort_df.head(20))\n",
    "# print(info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25855fe",
   "metadata": {},
   "source": [
    "# 신규광고 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 신규(가상) 광고 → 유사 광고 코호트 기반 매체별 CVR/전환수 예측 (원샷 셀)\n",
    "# ==============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------- 파일 경로 -----------------\n",
    "PERF_CSV = \"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/수정_시간별적립보고서(최종).csv\"   # 시간별 집계(또는 로그)\n",
    "META_CSV = \"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/광고도메인리스트.csv\"             # 기존 광고 메타(ads_idx 존재)\n",
    "NEW_ADS_CSV = \"/Users/Jiwon/Documents/GitHub/final_project/Jiwon/신규가상광고.csv\"                                                    # 신규 가상광고 목록\n",
    "\n",
    "# ----------------- 하이퍼파라미터 -----------------\n",
    "L_DAYS = 30                 # 예측에 사용할 과거 창 길이\n",
    "H_DAYS = 30                 # 시나리오B(향후 H일) 클릭/전환 예측 길이\n",
    "K = 10                      # 유사 광고 코호트 크기\n",
    "BETA_SIM = 1.0              # 유사도 가중 지수 (cos sim^beta)\n",
    "ALPHA_PRIOR = 2.0           # 베타-바이노믹 스무딩 alpha\n",
    "BETA_PRIOR = 120.0          # 베타-바이노믹 스무딩 beta\n",
    "BLEND_KAPPA = 15.0          # 블렌딩 전환: eff/(eff+kappa)\n",
    "DOMAIN_WEIGHT = 1.0         # 도메인 가중치(영향 키우려면 2~3)\n",
    "RESTRICT_SAME_DOMAIN = False# True면 같은 도메인 후보만 코호트로\n",
    "DROP_RARE_MIN_ADS = 3       # 희귀 원-핫 열 제거(3개 미만 광고에서만 등장)\n",
    "\n",
    "CAT_COLS = [\"domain\", \"ads_category\", \"ads_os_type\", \"ads_type\", \"ads_rejoin_type\"]\n",
    "PRICE_CANDIDATES = (\"ads_media_price\", \"media_price\", \"contract_price\")\n",
    "\n",
    "# ----------------- 작은 유틸 -----------------\n",
    "def _norm_meta(df):\n",
    "    df = df.copy()\n",
    "    for c in CAT_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def _pick_date_col(df):\n",
    "    for c in [\"rpt_time_date\",\"click_day\",\"click_date\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(\"날짜 컬럼(rpt_time_date / click_day / click_date) 없음\")\n",
    "\n",
    "def _clicks_convs_cols(df):\n",
    "    clicks = None; convs = None\n",
    "    if \"rpt_time_clk\" in df.columns: clicks = \"rpt_time_clk\"\n",
    "    elif \"clicks\" in df.columns:     clicks = \"clicks\"\n",
    "    elif \"click_key\" in df.columns:  clicks = None           # 로그면 size()로 산출\n",
    "\n",
    "    if \"rpt_time_turn\" in df.columns: convs = \"rpt_time_turn\"\n",
    "    elif \"conversions\" in df.columns: convs = \"conversions\"\n",
    "    elif \"conversion\" in df.columns:  convs = \"conversion\"\n",
    "    return clicks, convs\n",
    "\n",
    "def _z(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    mu, sd = np.nanmean(s), np.nanstd(s)\n",
    "    sd = 1.0 if (sd is None or sd == 0 or np.isnan(sd)) else sd\n",
    "    return (s - mu) / sd, float(mu), float(sd)\n",
    "\n",
    "# ----------------- 1) 기존 광고로 피처 공간 학습 -----------------\n",
    "def build_feature_space(ad_meta, drop_rare_min_ads=3, domain_weight=1.0):\n",
    "    meta = _norm_meta(ad_meta).drop_duplicates(\"ads_idx\").copy()\n",
    "\n",
    "    X_list = []\n",
    "    group_cols = {}\n",
    "\n",
    "    # (a) 범주형 원-핫\n",
    "    for c in CAT_COLS:\n",
    "        if c in meta.columns:\n",
    "            one = pd.get_dummies(meta[c].astype(str), prefix=c, dtype=float)\n",
    "            if c == \"domain\" and domain_weight != 1.0:\n",
    "                one = one * float(domain_weight)\n",
    "            X_list.append(one)\n",
    "            group_cols[c] = list(one.columns)\n",
    "\n",
    "    # (b) 수치형(가격) - 후보 중 존재하는 첫 컬럼 사용\n",
    "    price_col = next((c for c in PRICE_CANDIDATES if c in meta.columns), None)\n",
    "    price_mu = price_sd = None\n",
    "    if price_col is not None:\n",
    "        price_log = np.log1p(pd.to_numeric(meta[price_col], errors=\"coerce\"))\n",
    "        price_z, price_mu, price_sd = _z(price_log)\n",
    "        X_list.append(price_z.to_frame(\"price_z\"))\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"ad_meta에서 만들 수 있는 피처가 없습니다.\")\n",
    "\n",
    "    X = pd.concat(X_list, axis=1).fillna(0.0)\n",
    "    # 희귀 원-핫 열 제거\n",
    "    if drop_rare_min_ads and drop_rare_min_ads > 1:\n",
    "        nz = (X != 0).sum(0)\n",
    "        keep = nz[nz >= float(drop_rare_min_ads)].index\n",
    "        X = X[keep]\n",
    "        # 그룹 열 목록 갱신\n",
    "        for g in list(group_cols.keys()):\n",
    "            group_cols[g] = [col for col in group_cols[g] if col in X.columns]\n",
    "\n",
    "    # z-score (열 단위)\n",
    "    mu = X.mean()\n",
    "    sd = X.std(ddof=0).replace(0, 1.0)\n",
    "    A_z = (X - mu) / (sd + 1e-9)\n",
    "    A_z.index = meta[\"ads_idx\"].astype(int).values\n",
    "\n",
    "    store = dict(\n",
    "        A_z=A_z.astype(np.float32),\n",
    "        mu=mu.astype(np.float32), sd=sd.astype(np.float32),\n",
    "        cols=A_z.columns.tolist(),\n",
    "        group_cols=group_cols,\n",
    "        price_col=price_col,\n",
    "        price_mu=price_mu, price_sd=price_sd,\n",
    "        meta_small=meta[[\"ads_idx\"] + [c for c in CAT_COLS if c in meta.columns]]\n",
    "    )\n",
    "    return store\n",
    "\n",
    "# ----------------- 2) 신규 광고 1건 인코딩(기존 공간에 맞춤) -----------------\n",
    "def encode_new_ad_row(row, store):\n",
    "    cols = store[\"cols\"]\n",
    "    x = pd.Series(0.0, index=cols, dtype=float)\n",
    "\n",
    "    # 범주형: 기존에 있던 열만 1로 세움(새로운 카테고리는 정보 없음 → 0)\n",
    "    for c in CAT_COLS:\n",
    "        if c in row.index:\n",
    "            val = str(row[c]).strip()\n",
    "            one_col = f\"{c}_{val}\"\n",
    "            if one_col in x.index:\n",
    "                x[one_col] = 1.0\n",
    "\n",
    "    # 가격: log1p 후 기존 z스케일 사용\n",
    "    pcol = store[\"price_col\"]\n",
    "    if pcol and pcol in row.index:\n",
    "        val = pd.to_numeric(row[pcol], errors=\"coerce\")\n",
    "        if pd.notnull(val):\n",
    "            z = (np.log1p(val) - store[\"price_mu\"]) / (store[\"price_sd\"] + 1e-9)\n",
    "            if \"price_z\" in x.index:\n",
    "                x[\"price_z\"] = float(z)\n",
    "\n",
    "    # L2 정규화용 벡터 반환\n",
    "    a = x.values.astype(np.float32)\n",
    "    a = a / (np.linalg.norm(a) + 1e-12)\n",
    "    return x, a\n",
    "\n",
    "# ----------------- 3) 신규 광고 → 유사 광고 코호트 추출 -----------------\n",
    "def cohort_for_new_ad(row, store, K=50, beta=BETA_SIM, restrict_same_domain=False):\n",
    "    A = store[\"A_z\"]\n",
    "    # 후보 제한(같은 도메인)\n",
    "    cand = A\n",
    "    if restrict_same_domain and \"domain\" in row.index and \"domain\" in store[\"meta_small\"].columns:\n",
    "        dom = str(row[\"domain\"]).strip()\n",
    "        ok_ids = store[\"meta_small\"].loc[\n",
    "            store[\"meta_small\"][\"domain\"].astype(str).str.strip() == dom, \"ads_idx\"\n",
    "        ].astype(int)\n",
    "        cand = A.loc[A.index.intersection(ok_ids)]\n",
    "\n",
    "    # 인코딩\n",
    "    x, a = encode_new_ad_row(row, store)\n",
    "    M = cand.values\n",
    "    norms = np.sqrt((M*M).sum(1)) + 1e-12\n",
    "    sims = (M @ a) / norms\n",
    "\n",
    "    if len(sims) == 0:\n",
    "        return pd.DataFrame(columns=[\"weight\",\"sim\"])\n",
    "\n",
    "    k = min(K, len(sims))\n",
    "    top = np.argpartition(-sims, k-1)[:k]\n",
    "    top = top[np.argsort(-sims[top])]\n",
    "\n",
    "    sim_vals = sims[top]\n",
    "    w = np.power(np.clip(sim_vals, 0, 1), beta); w = w / (w.sum() + 1e-12)\n",
    "\n",
    "    out = pd.DataFrame({\"ads_idx\": cand.index.values[top].astype(int),\n",
    "                        \"sim\": sim_vals, \"weight\": w})\n",
    "    out = out.set_index(\"ads_idx\")\n",
    "    return out\n",
    "\n",
    "# ----------------- 4) 코호트 기반 매체사 CVR/전환수 예측 -----------------\n",
    "def predict_media_from_cohort(perf_df, ad_meta_df, cohort_df, new_row,\n",
    "                              L_days=30, H_days=30,\n",
    "                              alpha_prior=ALPHA_PRIOR, beta_prior=BETA_PRIOR,\n",
    "                              blend_kappa=BLEND_KAPPA):\n",
    "    if cohort_df.empty:\n",
    "        return pd.DataFrame(), {\"window_end\": None, \"L_days\": L_days, \"H_days\": H_days}\n",
    "\n",
    "    perf = perf_df.copy()\n",
    "    date_col = _pick_date_col(perf)\n",
    "    perf[date_col] = pd.to_datetime(perf[date_col])\n",
    "    wend = perf[date_col].max().normalize()\n",
    "    start = wend - pd.Timedelta(days=L_days-1)\n",
    "    hist = perf[(perf[date_col]>=start) & (perf[date_col]<=wend)].copy()\n",
    "\n",
    "    clk_col, cv_col = _clicks_convs_cols(hist)\n",
    "\n",
    "    # ads_category를 히스토리에 붙임(매체×카테 베이스라인용)\n",
    "    if \"ads_category\" in ad_meta_df.columns and \"ads_category\" not in hist.columns:\n",
    "        cat_map = ad_meta_df.drop_duplicates(\"ads_idx\").set_index(\"ads_idx\")[\"ads_category\"]\n",
    "        hist = hist.merge(cat_map.rename(\"ads_category\"), left_on=\"ads_idx\", right_index=True, how=\"left\")\n",
    "\n",
    "    # 코호트 가중 집계\n",
    "    sub = hist[hist[\"ads_idx\"].isin(cohort_df.index)].copy()\n",
    "    if sub.empty:\n",
    "        return pd.DataFrame(), {\"window_end\": str(wend.date()), \"L_days\": L_days, \"H_days\": H_days}\n",
    "\n",
    "    if clk_col is None:\n",
    "        g = sub.groupby([\"ads_idx\",\"mda_idx\"]).agg(\n",
    "            clicks=(\"ads_idx\",\"size\"), convs=(\"conversion\",\"sum\")\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        g = sub.groupby([\"ads_idx\",\"mda_idx\"]).agg(\n",
    "            clicks=(clk_col,\"sum\"), convs=(cv_col,\"sum\")\n",
    "        ).reset_index()\n",
    "\n",
    "    w_map = cohort_df[\"weight\"].to_dict()\n",
    "    g[\"w\"] = g[\"ads_idx\"].map(w_map).fillna(0.0)\n",
    "    g[\"w_clicks\"] = g[\"w\"] * g[\"clicks\"]\n",
    "    g[\"w_convs\"]  = g[\"w\"] * g[\"convs\"]\n",
    "\n",
    "    agg = g.groupby(\"mda_idx\").agg(\n",
    "        cohort_eff_clicks=(\"w_clicks\",\"sum\"),\n",
    "        cohort_eff_convs=(\"w_convs\",\"sum\"),\n",
    "        coverage_ads=(\"ads_idx\",\"nunique\")\n",
    "    )\n",
    "\n",
    "    # 베이스라인 (매체 전체)\n",
    "    if clk_col is None:\n",
    "        base_m = hist.groupby(\"mda_idx\").agg(\n",
    "            clicks=(\"ads_idx\",\"size\"), convs=(\"conversion\",\"sum\")\n",
    "        )\n",
    "    else:\n",
    "        base_m = hist.groupby(\"mda_idx\").agg(\n",
    "            clicks=(clk_col,\"sum\"), convs=(cv_col,\"sum\")\n",
    "        )\n",
    "    base_m[\"cvr_m\"] = (base_m[\"convs\"] + alpha_prior) / (base_m[\"clicks\"] + alpha_prior + beta_prior)\n",
    "\n",
    "    # 베이스라인 (매체×카테고리: 신규 광고의 카테고리 사용)\n",
    "    tcat = None\n",
    "    if \"ads_category\" in new_row.index:\n",
    "        try:\n",
    "            tcat = int(pd.to_numeric(new_row[\"ads_category\"], errors=\"coerce\"))\n",
    "        except Exception:\n",
    "            tcat = None\n",
    "\n",
    "    base_mc = pd.DataFrame()\n",
    "    if (tcat is not None) and (\"ads_category\" in hist.columns):\n",
    "        subcat = hist[hist[\"ads_category\"]==tcat]\n",
    "        if not subcat.empty:\n",
    "            if clk_col is None:\n",
    "                base_mc = subcat.groupby(\"mda_idx\").agg(\n",
    "                    clicks=(\"ads_idx\",\"size\"), convs=(\"conversion\",\"sum\")\n",
    "                )\n",
    "            else:\n",
    "                base_mc = subcat.groupby(\"mda_idx\").agg(\n",
    "                    clicks=(clk_col,\"sum\"), convs=(cv_col,\"sum\")\n",
    "                )\n",
    "            base_mc[\"cvr_mc\"] = (base_mc[\"convs\"] + alpha_prior) / (base_mc[\"clicks\"] + alpha_prior + beta_prior)\n",
    "\n",
    "    out = agg.join(base_m[[\"cvr_m\"]], how=\"left\").join(base_mc[[\"cvr_mc\"]], how=\"left\").fillna({\"cvr_m\":0.0})\n",
    "    out[\"cvr_cohort\"] = (out[\"cohort_eff_convs\"] + alpha_prior) / (out[\"cohort_eff_clicks\"] + alpha_prior + beta_prior)\n",
    "    base = out[\"cvr_mc\"].fillna(out[\"cvr_m\"])\n",
    "    eff = out[\"cohort_eff_clicks\"]\n",
    "    w1 = eff / (eff + float(blend_kappa))\n",
    "    out[\"pred_cvr\"] = w1 * out[\"cvr_cohort\"] + (1.0 - w1) * base\n",
    "    out[\"per_1000_clicks_conv\"] = out[\"pred_cvr\"] * 1000.0\n",
    "\n",
    "    # 시나리오: 코호트 일평균 클릭 × H_days\n",
    "    if clk_col is None:\n",
    "        per_day = (sub.groupby([\"mda_idx\", sub[date_col].dt.normalize()])[\"ads_idx\"]\n",
    "                   .size().rename(\"clk\").reset_index())\n",
    "    else:\n",
    "        per_day = (sub.groupby([\"mda_idx\", sub[date_col].dt.normalize()])[clk_col]\n",
    "                   .sum().rename(\"clk\").reset_index())\n",
    "    daily = per_day.groupby(\"mda_idx\")[\"clk\"].mean()\n",
    "    out[\"scenarioB_clicks\"] = daily.reindex(out.index).fillna(0.0).values * float(H_DAYS)\n",
    "    out[\"scenarioB_conv\"]   = out[\"pred_cvr\"] * out[\"scenarioB_clicks\"]\n",
    "\n",
    "    out = out.reset_index().sort_values(\"per_1000_clicks_conv\", ascending=False).reset_index(drop=True)\n",
    "    info = {\"window_end\": str(wend.date()), \"L_days\": L_DAYS, \"H_days\": H_DAYS}\n",
    "    return out, info\n",
    "\n",
    "# ----------------- 5) 배치 실행: 신규 광고 목록 전체 처리 -----------------\n",
    "def run_new_ads_batch(new_ads_df, ad_meta_df, perf_df,\n",
    "                      topN_media=20, show_first_n=1):\n",
    "    store = build_feature_space(ad_meta_df, drop_rare_min_ads=DROP_RARE_MIN_ADS,\n",
    "                                domain_weight=DOMAIN_WEIGHT)\n",
    "\n",
    "    results = {}  # key: new_ad_key → (pred_df, cohort_df, info)\n",
    "    key_col = \"ads_idx\" if \"ads_idx\" in new_ads_df.columns else None\n",
    "\n",
    "    for i, row in new_ads_df.iterrows():\n",
    "        new_key = int(row[key_col]) if key_col else int(i)\n",
    "        cohort = cohort_for_new_ad(row, store, K=K, beta=BETA_SIM,\n",
    "                                   restrict_same_domain=RESTRICT_SAME_DOMAIN)\n",
    "        pred, info = predict_media_from_cohort(perf_df, ad_meta_df, cohort, row,\n",
    "                                               L_days=L_DAYS, H_days=H_DAYS,\n",
    "                                               alpha_prior=ALPHA_PRIOR, beta_prior=BETA_PRIOR,\n",
    "                                               blend_kappa=BLEND_KAPPA)\n",
    "        results[new_key] = (pred, cohort, info)\n",
    "\n",
    "    # 미리보기: show_first_n > 0 인 경우에만 출력\n",
    "    if show_first_n and show_first_n > 0:\n",
    "        shown = 0\n",
    "        for k, (pred, cohort, info) in results.items():\n",
    "            print(f\"\\n=== 신규광고 {k} : window_end={info['window_end']}, L_days={info['L_days']} ===\")\n",
    "\n",
    "            if cohort is not None and not cohort.empty:\n",
    "                disp = cohort.reset_index()[[\"ads_idx\",\"sim\",\"weight\"]].head(10)\n",
    "                try:\n",
    "                    display(disp.style.format({\"sim\":\"{:.3f}\",\"weight\":\"{:.3f}\"}))\n",
    "                except Exception:\n",
    "                    print(disp.to_string(index=False))\n",
    "            else:\n",
    "                print(\"코호트가 비어 있습니다.\")\n",
    "\n",
    "            if pred is not None and not pred.empty:\n",
    "                cols = [\"mda_idx\",\"pred_cvr\",\"per_1000_clicks_conv\",\n",
    "                        \"cohort_eff_clicks\",\"coverage_ads\",\n",
    "                        \"cvr_m\",\"cvr_mc\",\"cvr_cohort\",\n",
    "                        \"scenarioB_clicks\",\"scenarioB_conv\"]\n",
    "                view = pred.head(topN_media)[[c for c in cols if c in pred.columns]]\n",
    "                try:\n",
    "                    display(view.style.format({\n",
    "                        \"pred_cvr\":\"{:.6f}\", \"per_1000_clicks_conv\":\"{:.3f}\",\n",
    "                        \"cvr_m\":\"{:.6f}\", \"cvr_mc\":\"{:.6f}\", \"cvr_cohort\":\"{:.6f}\",\n",
    "                        \"scenarioB_clicks\":\"{:.3f}\", \"scenarioB_conv\":\"{:.3f}\"\n",
    "                    }))\n",
    "                except Exception:\n",
    "                    print(view.to_string(index=False))\n",
    "            else:\n",
    "                print(\"히스토리 구간에서 코호트 데이터가 없습니다.\")\n",
    "\n",
    "            shown += 1\n",
    "            if shown >= show_first_n:\n",
    "                break\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9faf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 실행 (단일 ads_idx만 미리보기) ==================\n",
    "# 1) 데이터 로드\n",
    "perf_df = pd.read_csv(PERF_CSV, encoding=\"utf-8-sig\")\n",
    "ad_meta_df = pd.read_csv(META_CSV, encoding=\"utf-8-sig\")\n",
    "new_ads_df = pd.read_csv(NEW_ADS_CSV, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 2) sanity check\n",
    "assert \"ads_idx\" in new_ads_df.columns, \"new_ads_df에 'ads_idx' 컬럼이 없습니다.\"\n",
    "\n",
    "# 3) 모든 신규광고에 대해 계산만 수행(미리보기 출력 없음)\n",
    "results = run_new_ads_batch(new_ads_df, ad_meta_df, perf_df,\n",
    "                            topN_media=20, show_first_n=0)\n",
    "\n",
    "target_ads_idx = 500005  \n",
    "\n",
    "if target_ads_idx not in results:\n",
    "    print(f\"[!] ads_idx {target_ads_idx} 가 results에 없습니다. new_ads_df에 있는지 확인하세요.\")\n",
    "else:\n",
    "    pred, cohort, info = results[target_ads_idx]\n",
    "\n",
    "# 코호트 상위 10개\n",
    "if cohort is not None and not cohort.empty:\n",
    "    disp = cohort.reset_index()[[\"ads_idx\",\"sim\",\"weight\"]].head(10)\n",
    "    try:\n",
    "        display(disp.style.format({\"sim\":\"{:.3f}\",\"weight\":\"{:.3f}\"}))\n",
    "    except Exception:\n",
    "        print(disp.to_string(index=False))\n",
    "else:\n",
    "    print(\"코호트가 비어 있습니다.\")\n",
    "\n",
    "# 매체사 추천 테이블(topN_media)\n",
    "if pred is not None and not pred.empty:\n",
    "    cols = [\"mda_idx\",\"pred_cvr\",\"per_1000_clicks_conv\",\n",
    "            \"cohort_eff_clicks\",\"coverage_ads\",\n",
    "            \"cvr_m\",\"cvr_mc\",\"cvr_cohort\",\n",
    "            \"scenarioB_clicks\",\"scenarioB_conv\"]\n",
    "    view = pred.head(20)[[c for c in cols if c in pred.columns]]\n",
    "    try:\n",
    "        display(view.style.format({\n",
    "            \"pred_cvr\":\"{:.6f}\", \"per_1000_clicks_conv\":\"{:.3f}\",\n",
    "            \"cvr_m\":\"{:.6f}\", \"cvr_mc\":\"{:.6f}\", \"cvr_cohort\":\"{:.6f}\",\n",
    "            \"scenarioB_clicks\":\"{:.3f}\", \"scenarioB_conv\":\"{:.3f}\"\n",
    "        }))\n",
    "    except Exception:\n",
    "        print(view.to_string(index=False))\n",
    "else:\n",
    "    print(\"히스토리 구간에서 코호트 데이터가 없습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wonv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
